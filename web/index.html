<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Abby Unleashed</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        :root {
            --primary: #6366f1;
            --primary-glow: rgba(99, 102, 241, 0.4);
            --success: #10b981;
            --error: #ef4444;
            --bg: #0f172a;
            --bg-dark: #020617;
            --surface: #1e293b;
            --surface-light: #334155;
            --text: #f1f5f9;
            --text-muted: #94a3b8;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg);
            color: var(--text);
            height: 100vh;
            height: 100dvh;
            overflow: hidden;
        }
        
        /* ============ TEXT CHAT MODE ============ */
        #chatMode {
            display: flex;
            flex-direction: column;
            height: 100%;
        }
        
        .header {
            background: var(--surface);
            padding: 1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--surface-light);
        }
        
        .header-left {
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: var(--success);
            box-shadow: 0 0 8px var(--success);
        }
        
        .status-dot.offline { background: var(--error); box-shadow: 0 0 8px var(--error); }
        
        .header h1 {
            font-size: 1.25rem;
            font-weight: 600;
        }
        
        /* User Identity Selector */
        .user-selector {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .user-select-btn {
            background: var(--surface-light);
            border: 2px solid var(--primary);
            color: var(--text);
            padding: 0.4rem 0.8rem;
            border-radius: 1.5rem;
            font-size: 0.8rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.4rem;
            transition: all 0.2s;
        }
        
        .user-select-btn:hover {
            background: var(--primary);
            transform: scale(1.02);
        }
        
        .user-select-btn.identified {
            background: linear-gradient(135deg, var(--success), #059669);
            border-color: var(--success);
        }
        
        .user-modal {
            display: none;
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.8);
            z-index: 2000;
            align-items: center;
            justify-content: center;
            padding: 1rem;
        }
        
        .user-modal.active {
            display: flex;
        }
        
        .user-modal-content {
            background: var(--surface);
            border-radius: 1rem;
            padding: 1.5rem;
            max-width: 400px;
            width: 100%;
            animation: modalIn 0.2s ease;
        }
        
        @keyframes modalIn {
            from { opacity: 0; transform: scale(0.9); }
            to { opacity: 1; transform: scale(1); }
        }
        
        .user-modal h2 {
            margin-bottom: 1rem;
            font-size: 1.2rem;
            text-align: center;
        }
        
        .user-modal-subtitle {
            color: var(--text-muted);
            font-size: 0.9rem;
            text-align: center;
            margin-bottom: 1.5rem;
        }
        
        .user-option {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 1rem;
            background: var(--bg);
            border-radius: 0.75rem;
            margin-bottom: 0.75rem;
            cursor: pointer;
            transition: all 0.2s;
            border: 2px solid transparent;
        }
        
        .user-option:hover {
            border-color: var(--primary);
            transform: translateX(4px);
        }
        
        .user-option.selected {
            border-color: var(--success);
            background: rgba(16, 185, 129, 0.1);
        }
        
        .user-option-icon {
            width: 48px;
            height: 48px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary), #8b5cf6);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
        }
        
        .user-option.organic .user-option-icon {
            background: linear-gradient(135deg, #ec4899, #f472b6);
        }
        
        .user-option.boyfriend .user-option-icon {
            background: linear-gradient(135deg, #f59e0b, #fbbf24);
        }
        
        .user-option-info {
            flex: 1;
        }
        
        .user-option-name {
            font-weight: 600;
            margin-bottom: 0.25rem;
        }
        
        .user-option-desc {
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .user-modal-close {
            margin-top: 1rem;
            width: 100%;
            padding: 0.75rem;
            background: var(--surface-light);
            border: none;
            color: var(--text);
            border-radius: 0.5rem;
            cursor: pointer;
            font-size: 0.9rem;
        }
        
        .user-modal-close:hover {
            background: var(--primary);
        }
        
        .voice-mode-btn {
            background: linear-gradient(135deg, var(--primary), #8b5cf6);
            border: none;
            color: white;
            padding: 0.6rem 1rem;
            border-radius: 2rem;
            font-size: 0.9rem;
            font-weight: 500;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            transition: all 0.3s;
        }
        
        .voice-mode-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 20px var(--primary-glow);
        }
        
        /* ============ ADMIN TOOLBAR ============ */
        .admin-toolbar {
            background: var(--bg-dark);
            border-bottom: 1px solid var(--surface-light);
            padding: 0.5rem 1rem;
            display: flex;
            align-items: center;
            gap: 1rem;
            font-size: 0.8rem;
        }
        
        .admin-toolbar-group {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .admin-btn {
            background: var(--surface);
            border: 1px solid var(--surface-light);
            color: var(--text-muted);
            padding: 0.35rem 0.7rem;
            border-radius: 0.4rem;
            font-size: 0.75rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.3rem;
            transition: all 0.2s;
        }
        
        .admin-btn:hover {
            background: var(--surface-light);
            color: var(--text);
        }
        
        .admin-btn.active {
            background: var(--primary);
            border-color: var(--primary);
            color: white;
        }
        
        .ngrok-status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--text-muted);
            font-size: 0.75rem;
        }
        
        .ngrok-status.connected {
            color: var(--success);
        }
        
        .ngrok-url {
            background: var(--surface);
            padding: 0.25rem 0.5rem;
            border-radius: 0.3rem;
            font-family: monospace;
            font-size: 0.7rem;
            max-width: 200px;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
            cursor: pointer;
        }
        
        .ngrok-url:hover {
            background: var(--surface-light);
        }
        
        /* Server Logs Panel */
        .logs-panel {
            display: none;
            background: var(--bg-dark);
            border-bottom: 1px solid var(--surface-light);
            max-height: 200px;
            overflow-y: auto;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 0.7rem;
        }
        
        .logs-panel.active {
            display: block;
        }
        
        .log-entry {
            padding: 0.2rem 0.75rem;
            border-bottom: 1px solid rgba(255,255,255,0.05);
            display: flex;
            gap: 0.5rem;
        }
        
        .log-entry:hover {
            background: var(--surface);
        }
        
        .log-time {
            color: var(--text-muted);
            min-width: 70px;
        }
        
        .log-level {
            min-width: 50px;
            font-weight: 600;
        }
        
        .log-level.INFO { color: #3b82f6; }
        .log-level.WARNING { color: #f59e0b; }
        .log-level.ERROR { color: #ef4444; }
        .log-level.DEBUG { color: #8b5cf6; }
        
        .log-message {
            color: var(--text);
            word-break: break-all;
        }
        
        .logs-panel-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.4rem 0.75rem;
            background: var(--surface);
            position: sticky;
            top: 0;
            z-index: 1;
        }
        
        .logs-panel-title {
            font-weight: 600;
            color: var(--text);
        }
        
        .logs-panel-actions {
            display: flex;
            gap: 0.5rem;
        }
        
        .logs-panel-btn {
            background: transparent;
            border: none;
            color: var(--text-muted);
            cursor: pointer;
            padding: 0.2rem;
            font-size: 0.8rem;
        }
        
        .logs-panel-btn:hover {
            color: var(--text);
        }

        .messages {
            flex: 1;
            overflow-y: auto;
            padding: 1rem;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .msg {
            display: flex;
            gap: 0.75rem;
            max-width: 85%;
            animation: fadeIn 0.3s ease;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .msg.user {
            flex-direction: row-reverse;
            align-self: flex-end;
        }
        
        .avatar {
            width: 36px;
            height: 36px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            font-size: 0.9rem;
            flex-shrink: 0;
        }
        
        .msg:not(.user) .avatar {
            background: linear-gradient(135deg, var(--primary), #8b5cf6);
        }
        
        .msg.user .avatar {
            background: var(--surface-light);
        }
        
        .content {
            background: var(--surface);
            padding: 0.85rem 1rem;
            border-radius: 1.25rem;
            line-height: 1.5;
            font-size: 0.95rem;
        }
        
        .msg.user .content {
            background: linear-gradient(135deg, var(--primary), #7c3aed);
            border-bottom-right-radius: 0.25rem;
        }
        
        .msg:not(.user) .content {
            border-bottom-left-radius: 0.25rem;
        }
        
        /* Streaming/Thinking states */
        .msg.thinking .content {
            background: var(--surface-light);
            font-style: italic;
            color: var(--text-muted);
        }
        
        .msg.thinking .avatar {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.6; }
        }
        
        .typing-indicator {
            display: inline-flex;
            gap: 4px;
            padding: 4px 0;
        }
        
        .typing-indicator span {
            width: 8px;
            height: 8px;
            background: var(--text-muted);
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }
        
        .typing-indicator span:nth-child(2) { animation-delay: 0.2s; }
        .typing-indicator span:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes typing {
            0%, 60%, 100% { transform: translateY(0); }
            30% { transform: translateY(-6px); }
        }
        
        .step-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 0.75rem;
            background: var(--surface-light);
            border-radius: 0.5rem;
            font-size: 0.85rem;
            margin: 0.5rem 0;
        }
        
        .step-indicator.completed { border-left: 3px solid var(--success); }
        .step-indicator.in-progress { border-left: 3px solid var(--primary); }
        
        .interrupt-btn {
            position: fixed;
            bottom: 100px;
            right: 20px;
            padding: 0.75rem 1.25rem;
            background: var(--error);
            color: white;
            border: none;
            border-radius: 2rem;
            cursor: pointer;
            font-weight: 600;
            display: none;
            z-index: 100;
            animation: fadeIn 0.2s ease;
        }
        
        .interrupt-btn:hover {
            background: #dc2626;
        }
        
        .interrupt-btn.visible {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .input-area {
            background: var(--surface);
            padding: 1rem;
            display: flex;
            gap: 0.75rem;
            border-top: 1px solid var(--surface-light);
        }
        
        #textInput {
            flex: 1;
            padding: 0.85rem 1.25rem;
            background: var(--bg);
            border: 2px solid var(--surface-light);
            border-radius: 1.5rem;
            color: var(--text);
            font-size: 1rem;
            outline: none;
            transition: border-color 0.2s;
        }
        
        #textInput:focus {
            border-color: var(--primary);
        }
        
        #textInput::placeholder {
            color: var(--text-muted);
        }
        
        .send-btn {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary), #8b5cf6);
            border: none;
            color: white;
            font-size: 1.25rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
        }
        
        .send-btn:hover:not(:disabled) {
            transform: scale(1.05);
        }
        
        .send-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        /* ============ VOICE MODE ============ */
        #voiceMode {
            display: none;
            position: fixed;
            inset: 0;
            background: linear-gradient(180deg, var(--bg-dark) 0%, var(--bg) 50%, var(--bg-dark) 100%);
            flex-direction: column;
            align-items: center;
            justify-content: space-between;
            padding: 2rem 1.5rem;
            z-index: 1000;
        }
        
        #voiceMode.active {
            display: flex;
        }
        
        .voice-header {
            width: 100%;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .close-voice-btn {
            background: var(--surface);
            border: none;
            color: var(--text);
            width: 44px;
            height: 44px;
            border-radius: 50%;
            font-size: 1.5rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
        }
        
        .close-voice-btn:hover {
            background: var(--surface-light);
        }
        
        .voice-status {
            font-size: 0.9rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        .model-badge {
            background: var(--surface);
            padding: 0.4rem 0.8rem;
            border-radius: 1rem;
            font-size: 0.75rem;
            color: var(--text-muted);
        }
        
        /* Avatar Container */
        .avatar-container {
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            flex: 1;
        }
        
        .avatar-ring {
            position: absolute;
            border-radius: 50%;
            border: 2px solid var(--primary);
            opacity: 0.3;
            animation: ring-pulse 2s ease-in-out infinite;
        }
        
        .avatar-ring:nth-child(1) { width: 200px; height: 200px; animation-delay: 0s; }
        .avatar-ring:nth-child(2) { width: 260px; height: 260px; animation-delay: 0.3s; }
        .avatar-ring:nth-child(3) { width: 320px; height: 320px; animation-delay: 0.6s; }
        
        @keyframes ring-pulse {
            0%, 100% { transform: scale(1); opacity: 0.3; }
            50% { transform: scale(1.05); opacity: 0.5; }
        }
        
        .main-avatar {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary), #8b5cf6, #ec4899);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 4rem;
            position: relative;
            z-index: 10;
            box-shadow: 0 0 60px var(--primary-glow);
            transition: transform 0.1s ease, box-shadow 0.1s ease;
        }
        
        .main-avatar.speaking {
            animation: avatar-speak 0.15s ease-in-out infinite alternate;
        }
        
        .main-avatar.listening {
            box-shadow: 0 0 80px rgba(16, 185, 129, 0.5);
        }
        
        @keyframes avatar-speak {
            0% { transform: scale(1); }
            100% { transform: scale(var(--speak-scale, 1.05)); }
        }
        
        /* Transcript Area */
        .transcript-area {
            width: 100%;
            min-height: 100px;
            max-height: 150px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.5rem;
            text-align: center;
            padding: 0 1rem;
        }
        
        .transcript-label {
            font-size: 0.75rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        .transcript-text {
            font-size: 1.1rem;
            line-height: 1.5;
            color: var(--text);
            max-height: 80px;
            overflow-y: auto;
        }
        
        .transcript-text.interim {
            color: #22c55e;
            font-style: italic;
            animation: pulse-green 0.5s ease-in-out;
        }
        
        /* Voice text fallback for when speech recognition doesn't work */
        .voice-text-fallback {
            display: flex;
            gap: 0.5rem;
            margin-top: 1rem;
            width: 100%;
            max-width: 300px;
        }
        
        .voice-text-fallback input {
            flex: 1;
            background: var(--surface);
            border: 1px solid var(--surface-light);
            border-radius: 1.5rem;
            padding: 0.6rem 1rem;
            color: var(--text);
            font-size: 0.9rem;
        }
        
        .voice-text-fallback input::placeholder {
            color: var(--text-muted);
        }
        
        .voice-text-fallback button {
            background: var(--primary);
            border: none;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 1rem;
        }

        @keyframes pulse-green {
            0%, 100% { color: #22c55e; }
            50% { color: #4ade80; }
        }
        
        .hearing-indicator {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 0.9rem;
            color: #22c55e;
            font-weight: bold;
            opacity: 0;
            transition: opacity 0.2s;
            pointer-events: none;
        }
        
        .hearing-indicator.active {
            opacity: 1;
            animation: pulse 1s infinite;
        }
        
        /* Voice Controls */
        .voice-controls {
            display: flex;
            gap: 1.5rem;
            align-items: center;
        }
        
        .mic-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary), #8b5cf6);
            color: white;
            font-size: 2rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 4px 30px var(--primary-glow);
            transition: all 0.2s;
            position: relative;
        }
        
        .mic-btn:hover {
            transform: scale(1.05);
        }
        
        .mic-btn.recording {
            background: linear-gradient(135deg, var(--error), #f97316);
            animation: mic-pulse 1s ease-in-out infinite;
        }
        
        @keyframes mic-pulse {
            0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.5); }
            50% { box-shadow: 0 0 0 20px rgba(239, 68, 68, 0); }
        }
        
        .mic-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .secondary-btn {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: 2px solid var(--surface-light);
            background: transparent;
            color: var(--text);
            font-size: 1.25rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
        }
        
        .secondary-btn:hover {
            background: var(--surface);
            border-color: var(--primary);
        }
        
        /* Mic Settings Modal */
        .mic-settings-modal {
            display: none;
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.85);
            z-index: 3000;
            align-items: center;
            justify-content: center;
            padding: 1rem;
        }
        
        .mic-settings-modal.active {
            display: flex;
        }
        
        .mic-settings-content {
            background: var(--surface);
            border-radius: 1rem;
            padding: 1.5rem;
            max-width: 400px;
            width: 100%;
            animation: modalIn 0.2s ease;
        }
        
        .mic-settings-content h3 {
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .mic-device-list {
            max-height: 300px;
            overflow-y: auto;
        }
        
        .mic-device-option {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 0.75rem;
            background: var(--bg);
            border-radius: 0.5rem;
            margin-bottom: 0.5rem;
            cursor: pointer;
            border: 2px solid transparent;
            transition: all 0.2s;
        }
        
        .mic-device-option:hover {
            border-color: var(--primary);
        }
        
        .mic-device-option.selected {
            border-color: var(--success);
            background: rgba(16, 185, 129, 0.1);
        }
        
        .mic-device-option .device-icon {
            font-size: 1.5rem;
        }
        
        .mic-device-option .device-info {
            flex: 1;
        }
        
        .mic-device-option .device-name {
            font-weight: 500;
            font-size: 0.9rem;
        }
        
        .mic-device-option .device-id {
            font-size: 0.7rem;
            color: var(--text-muted);
            font-family: monospace;
        }
        
        .mic-settings-footer {
            margin-top: 1rem;
            display: flex;
            gap: 0.5rem;
        }
        
        .mic-settings-footer button {
            flex: 1;
            padding: 0.75rem;
            border-radius: 0.5rem;
            border: none;
            cursor: pointer;
            font-weight: 500;
        }
        
        .mic-settings-footer .apply-btn {
            background: var(--primary);
            color: white;
        }
        
        .mic-settings-footer .cancel-btn {
            background: var(--surface-light);
            color: var(--text);
        }
        
        .mic-test-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-top: 1rem;
            padding: 0.5rem;
            background: var(--bg);
            border-radius: 0.5rem;
        }
        
        .mic-test-indicator .level-bar {
            flex: 1;
            height: 8px;
            background: var(--surface-light);
            border-radius: 4px;
            overflow: hidden;
        }
        
        .mic-test-indicator .level-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--success), #fbbf24, var(--error));
            width: 0%;
            transition: width 0.05s;
        }

        /* Audio Visualizer */
        .audio-visualizer {
            position: absolute;
            bottom: -30px;
            display: flex;
            gap: 3px;
            align-items: flex-end;
            height: 20px;
        }
        
        .visualizer-bar {
            width: 4px;
            background: var(--primary);
            border-radius: 2px;
            transition: height 0.05s ease;
        }
        
        /* Loading State */
        .thinking-indicator {
            display: none;
            align-items: center;
            gap: 0.5rem;
            color: var(--text-muted);
            font-size: 0.9rem;
        }
        
        .thinking-indicator.active {
            display: flex;
        }
        
        .thinking-dots {
            display: flex;
            gap: 4px;
        }
        
        .thinking-dots span {
            width: 8px;
            height: 8px;
            background: var(--primary);
            border-radius: 50%;
            animation: thinking 1.4s ease-in-out infinite;
        }
        
        .thinking-dots span:nth-child(2) { animation-delay: 0.2s; }
        .thinking-dots span:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes thinking {
            0%, 80%, 100% { transform: scale(0.6); opacity: 0.5; }
            40% { transform: scale(1); opacity: 1; }
        }
        
        /* ============ RICH DISPLAY PANEL ============ */
        .rich-display {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            max-height: 50vh;
            background: var(--bg-dark);
            border-top: 1px solid var(--surface-light);
            overflow-y: auto;
            transform: translateY(100%);
            transition: transform 0.3s ease;
            z-index: 1001;
            padding: 1rem;
        }
        
        .rich-display.active {
            transform: translateY(0);
        }
        
        .rich-display-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--surface-light);
        }
        
        .rich-display-title {
            font-weight: 600;
            color: var(--text);
        }
        
        .rich-display-toggle {
            background: none;
            border: none;
            color: var(--text-muted);
            font-size: 1.5rem;
            cursor: pointer;
            padding: 0.25rem;
        }
        
        .rich-content-item {
            margin-bottom: 1rem;
            background: var(--surface);
            border-radius: 0.75rem;
            overflow: hidden;
        }
        
        .rich-content-item.markdown {
            padding: 1rem;
            line-height: 1.6;
        }
        
        .rich-content-item.markdown h1,
        .rich-content-item.markdown h2,
        .rich-content-item.markdown h3 {
            margin-top: 1rem;
            margin-bottom: 0.5rem;
        }
        
        .rich-content-item.markdown code {
            background: var(--bg-dark);
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
        }
        
        .rich-content-item.markdown pre {
            background: var(--bg-dark);
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin: 0.5rem 0;
        }
        
        .rich-content-item.markdown pre code {
            background: none;
            padding: 0;
        }
        
        /* Inline code styling */
        .inline-code {
            background: var(--surface-light);
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
        }
        
        /* Code block styling for markdown */
        .code-block {
            margin: 1rem 0;
            border-radius: 0.5rem;
            overflow: hidden;
            background: #1e1e2e;
        }
        
        .code-block .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.5rem 1rem;
            background: #313244;
            font-size: 0.85rem;
            color: #cdd6f4;
        }
        
        .code-block pre {
            margin: 0;
            padding: 1rem;
            overflow-x: auto;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
            color: #cdd6f4;
        }
        
        .code-block .copy-btn {
            background: var(--primary);
            border: none;
            color: white;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            font-size: 0.75rem;
            cursor: pointer;
        }
        
        .code-block .copy-btn:hover {
            background: var(--primary-dark);
        }
        
        .rich-content-item.code {
            position: relative;
        }
        
        .rich-content-item.code .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.5rem 1rem;
            background: var(--surface-light);
            font-size: 0.85rem;
            color: var(--text-muted);
        }
        
        .rich-content-item.code pre {
            margin: 0;
            padding: 1rem;
            overflow-x: auto;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
        }
        
        .rich-content-item.code .copy-btn {
            background: var(--primary);
            border: none;
            color: white;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            font-size: 0.75rem;
            cursor: pointer;
        }
        
        .rich-content-item.image img {
            width: 100%;
            height: auto;
            display: block;
        }
        
        .rich-content-item.video {
            position: relative;
            padding-bottom: 56.25%;
            height: 0;
        }
        
        .rich-content-item.video iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
        
        .rich-content-item.link {
            padding: 1rem;
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        .rich-content-item.link a {
            color: var(--primary);
            text-decoration: none;
        }
        
        .rich-content-item.link a:hover {
            text-decoration: underline;
        }
        
        /* Hot mic indicator */
        .hot-mic-indicator {
            position: fixed;
            top: 1rem;
            right: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            background: rgba(239, 68, 68, 0.9);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 2rem;
            font-size: 0.85rem;
            font-weight: 500;
            z-index: 1002;
            opacity: 0;
            transform: translateY(-10px);
            transition: all 0.3s;
        }
        
        .hot-mic-indicator.active {
            opacity: 1;
            transform: translateY(0);
        }
        
        .hot-mic-indicator .dot {
            width: 8px;
            height: 8px;
            background: white;
            border-radius: 50%;
            animation: hot-mic-pulse 1s ease-in-out infinite;
        }
        
        @keyframes hot-mic-pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        
        /* Mini display preview in voice mode */
        .display-preview {
            position: absolute;
            bottom: 180px;
            left: 1rem;
            right: 1rem;
            max-height: 150px;
            overflow: hidden;
            background: var(--surface);
            border-radius: 1rem;
            padding: 0.75rem;
            font-size: 0.85rem;
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.3s;
        }
        
        .display-preview.active {
            opacity: 1;
            transform: translateY(0);
        }
        
        .display-preview-text {
            color: var(--text-muted);
            overflow: hidden;
            text-overflow: ellipsis;
            display: -webkit-box;
            -webkit-line-clamp: 4;
            -webkit-box-orient: vertical;
        }
        
        .display-preview-expand {
            display: flex;
            justify-content: center;
            margin-top: 0.5rem;
        }
        
        .display-preview-expand button {
            background: var(--primary);
            border: none;
            color: white;
            padding: 0.4rem 1rem;
            border-radius: 1rem;
            font-size: 0.8rem;
            cursor: pointer;
        }
        
        /* Base Modal Styles */
        .modal {
            display: none;
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.8);
            z-index: 2000;
            align-items: center;
            justify-content: center;
            padding: 1rem;
        }
        
        .modal.active {
            display: flex;
        }
        
        .modal-content {
            background: var(--surface);
            border-radius: 1rem;
            padding: 1.5rem;
            max-width: 500px;
            width: 100%;
            max-height: 90vh;
            overflow-y: auto;
            animation: modalIn 0.2s ease;
        }
        
        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }
        
        .modal-header h2 {
            margin: 0;
            font-size: 1.2rem;
        }
        
        .close-btn {
            background: none;
            border: none;
            color: var(--text-muted);
            font-size: 1.5rem;
            cursor: pointer;
            padding: 0.25rem;
            line-height: 1;
        }
        
        .close-btn:hover {
            color: var(--text);
        }
        
        /* Camera Modal Styles */
        .camera-modal {
            max-width: 500px;
        }
        
        .camera-container {
            position: relative;
            width: 100%;
            aspect-ratio: 4/3;
            background: #000;
            border-radius: 0.5rem;
            overflow: hidden;
            margin-bottom: 1rem;
        }
        
        .camera-container video {
            display: block !important;
            position: absolute;
            top: 0;
            left: 0;
            width: 100% !important;
            height: 100% !important;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror for natural feel */
            z-index: 1;
            background: transparent;
            -webkit-transform: scaleX(-1);
            opacity: 1 !important;
            visibility: visible !important;
        }
        
        .camera-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            pointer-events: none;
            z-index: 2;
        }
        
        .face-box {
            position: absolute;
            border: 3px solid #22c55e;
            border-radius: 0.25rem;
            display: none;
        }
        
        .face-box.unknown {
            border-color: #f59e0b;
        }
        
        .face-box::after {
            content: attr(data-name);
            position: absolute;
            bottom: -24px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.75rem;
            white-space: nowrap;
        }
        
        .camera-status {
            text-align: center;
            padding: 0.5rem;
            color: var(--text-muted);
            font-size: 0.9rem;
        }
        
        .camera-status.success { color: #22c55e; }
        .camera-status.error { color: #ef4444; }
        
        .camera-controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-bottom: 1rem;
        }
        
        .camera-action-btn {
            background: var(--primary);
            border: none;
            color: white;
            padding: 0.75rem 1.5rem;
            border-radius: 2rem;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        
        .camera-action-btn:hover {
            transform: scale(1.05);
        }
        
        .camera-action-btn.learn-btn {
            background: #8b5cf6;
        }
        
        .known-faces {
            border-top: 1px solid var(--border);
            padding-top: 1rem;
        }
        
        .known-faces h4 {
            margin: 0 0 0.5rem 0;
            color: var(--text-muted);
            font-size: 0.9rem;
        }
        
        .known-face-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
            background: var(--surface);
            border-radius: 0.5rem;
            margin-bottom: 0.5rem;
        }
        
        .known-face-item .face-icon {
            font-size: 1.5rem;
        }
        
        .known-face-item .face-info {
            flex: 1;
        }
        
        .known-face-item .face-name {
            font-weight: 600;
        }
        
        .known-face-item .face-samples {
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        /* Visual Awareness Toggle */
        .vision-toggle {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 0.75rem;
            background: var(--surface);
            border-radius: 0.5rem;
            margin-bottom: 1rem;
        }
        
        .vision-toggle-label {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-weight: 600;
        }
        
        .vision-toggle-label .icon { font-size: 1.25rem; }
        
        .toggle-switch {
            position: relative;
            width: 50px;
            height: 26px;
        }
        
        .toggle-switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }
        
        .toggle-slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #374151;
            transition: .3s;
            border-radius: 34px;
        }
        
        .toggle-slider:before {
            position: absolute;
            content: "";
            height: 20px;
            width: 20px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: .3s;
            border-radius: 50%;
        }
        
        input:checked + .toggle-slider {
            background-color: #22c55e;
        }
        
        input:checked + .toggle-slider:before {
            transform: translateX(24px);
        }
        
        /* Vision status indicator */
        .vision-status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: var(--surface);
            border-radius: 0.5rem;
            font-size: 0.85rem;
            margin-bottom: 1rem;
        }
        
        .vision-status .icon { animation: pulse 2s infinite; }
        
        .vision-status.watching { color: #22c55e; }
        .vision-status.not-watching { color: var(--text-muted); }
        
        /* Face detection boxes in live feed */
        .face-box.live {
            display: block;
            transition: all 0.1s;
        }
        
        .face-label {
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.75rem;
            white-space: nowrap;
            margin-bottom: 4px;
        }
        
        .expression-badge {
            position: absolute;
            top: -8px;
            right: -8px;
            background: var(--primary);
            padding: 2px 6px;
            border-radius: 10px;
            font-size: 0.7rem;
        }
        
        /* Camera button active state */
        #cameraBtn.watching {
            background: #22c55e !important;
            animation: pulse 2s infinite;
        }

        /* Responsive */
        @media (max-width: 400px) {
            .main-avatar { width: 120px; height: 120px; font-size: 3rem; }
            .avatar-ring:nth-child(1) { width: 160px; height: 160px; }
            .avatar-ring:nth-child(2) { width: 210px; height: 210px; }
            .avatar-ring:nth-child(3) { width: 260px; height: 260px; }
        }
    </style>
</head>
<body>
    <!-- INTERRUPT BUTTON (shown when Abby is thinking/working) -->
    <button class="interrupt-btn" id="interruptBtn" onclick="interruptAbby()">
        ‚èπÔ∏è Interrupt
    </button>

    <!-- HOT MIC INDICATOR -->
    <div class="hot-mic-indicator" id="hotMicIndicator">
        <div class="dot"></div>
        <span>Hot Mic Active</span>
    </div>

    <!-- TEXT CHAT MODE -->
    <div id="chatMode">
        <div class="header">
            <div class="header-left">
                <div class="status-dot" id="statusDot"></div>
                <h1>Abby</h1>
            </div>
            <div class="user-selector">
                <button class="user-select-btn" id="userSelectBtn" onclick="openUserModal()">
                    <span id="userIcon">üë§</span>
                    <span id="userName">Who's this?</span>
                </button>
                <button class="voice-mode-btn" onclick="enterVoiceMode()">
                    <span>üé§</span> Voice
                </button>
            </div>
        </div>
        
        <!-- Admin Toolbar -->
        <div class="admin-toolbar">
            <div class="admin-toolbar-group">
                <button class="admin-btn" id="logsToggle" onclick="toggleLogs()">
                    üìã Logs
                </button>
            </div>
            <div class="admin-toolbar-group">
                <button class="admin-btn" id="ngrokToggle" onclick="toggleNgrok()">
                    üåê Ngrok
                </button>
                <div class="ngrok-status" id="ngrokStatus">
                    <span id="ngrokStatusText">Disconnected</span>
                </div>
                <span class="ngrok-url" id="ngrokUrl" style="display: none;" onclick="copyNgrokUrl()" title="Click to copy"></span>
            </div>
        </div>
        
        <!-- Server Logs Panel -->
        <div class="logs-panel" id="logsPanel">
            <div class="logs-panel-header">
                <span class="logs-panel-title">üìã Server Logs</span>
                <div class="logs-panel-actions">
                    <button class="logs-panel-btn" onclick="clearLogs()" title="Clear logs">üóëÔ∏è</button>
                    <button class="logs-panel-btn" onclick="refreshLogs()" title="Refresh">üîÑ</button>
                    <button class="logs-panel-btn" onclick="toggleLogs()" title="Close">‚úï</button>
                </div>
            </div>
            <div id="logsContent"></div>
        </div>
        
        <div class="messages" id="messages">
            <div class="msg">
                <div class="avatar">A</div>
                <div class="content" id="welcomeMsg">üëã Hey! I'm Abby. How can I help you today?</div>
            </div>
        </div>
        
        <div class="input-area">
            <input type="text" id="textInput" placeholder="Type a message..." autocomplete="off">
            <button class="send-btn" id="sendBtn" onclick="sendTextMessage()">
                <span>‚û§</span>
            </button>
        </div>
    </div>
    
    <!-- VOICE MODE -->
    <div id="voiceMode">
        <div class="voice-header">
            <button class="close-voice-btn" onclick="exitVoiceMode()">‚úï</button>
            <div class="voice-status" id="voiceStatus">Ready</div>
            <div class="model-badge" id="modelBadge">mistral:latest</div>
        </div>
        
        <div class="avatar-container">
            <div class="avatar-ring"></div>
            <div class="avatar-ring"></div>
            <div class="avatar-ring"></div>
            <div class="main-avatar" id="mainAvatar">
                <span>ü§ñ</span>
            </div>
            <div class="audio-visualizer" id="audioVisualizer">
                <!-- Bars added dynamically -->
            </div>
        </div>
        
        <div class="transcript-area">
            <div class="transcript-label" id="transcriptLabel">Tap the mic to speak</div>
            <div class="transcript-text" id="transcriptText"></div>
            <div class="thinking-indicator" id="thinkingIndicator">
                <div class="thinking-dots">
                    <span></span><span></span><span></span>
                </div>
                <span>Thinking...</span>
            </div>
            <!-- Text input fallback for when voice doesn't work -->
            <div class="voice-text-fallback" id="voiceTextFallback">
                <input type="text" id="voiceTextInput" placeholder="Type here if voice isn't working..." autocomplete="off">
                <button onclick="sendVoiceText()">‚û§</button>
            </div>
        </div>
        
        <!-- Display Preview (shows while speaking) -->
        <div class="display-preview" id="displayPreview">
            <div class="display-preview-text" id="displayPreviewText"></div>
            <div class="display-preview-expand">
                <button onclick="toggleRichDisplay()">üìÑ View Full Response</button>
            </div>
        </div>
        
        <div class="voice-controls">
            <button class="secondary-btn" onclick="toggleHotMic()" id="hotMicBtn" title="Toggle Hot Mic">
                üî•
            </button>
            <button class="mic-btn" id="micBtn" onclick="toggleRecording()">
                üé§
            </button>
            <button class="secondary-btn" onclick="toggleMute()" id="muteBtn" title="Mute/Unmute">
                üîä
            </button>
            <button class="secondary-btn" onclick="testAudio()" id="testAudioBtn" title="Test Audio">
                üîî
            </button>
            <button class="secondary-btn" onclick="toggleCamera()" id="cameraBtn" title="Camera - Let Abby see you">
                üì∑
            </button>
            <button class="secondary-btn" onclick="openMicSettings()" id="micSettingsBtn" title="Mic Settings">
                ‚öôÔ∏è
            </button>
        </div>
    </div>
    
    <!-- MIC SETTINGS MODAL -->
    <div class="mic-settings-modal" id="micSettingsModal">
        <div class="mic-settings-content">
            <h3>üé§ Microphone Settings</h3>
            <p style="color: var(--text-muted); font-size: 0.85rem; margin-bottom: 1rem;">
                Select which microphone to use for voice input
            </p>
            <div class="mic-device-list" id="micDeviceList">
                <div style="color: var(--text-muted); padding: 1rem; text-align: center;">
                    Loading devices...
                </div>
            </div>
            <div class="mic-test-indicator">
                <span>üé§ Level:</span>
                <div class="level-bar">
                    <div class="level-fill" id="micLevelFill"></div>
                </div>
            </div>
            <div class="mic-settings-footer">
                <button class="cancel-btn" onclick="closeMicSettings()">Cancel</button>
                <button class="apply-btn" onclick="applyMicSettings()">Apply</button>
            </div>
        </div>
    </div>
    
    <!-- CAMERA MODAL -->
    <div class="modal" id="cameraModal">
        <div class="modal-content camera-modal">
            <div class="modal-header">
                <h2>ÔøΩÔ∏è Abby's Eyes</h2>
                <button class="close-btn" onclick="closeCameraModal()">‚úï</button>
            </div>
            
            <!-- Visual Awareness Toggle -->
            <div class="vision-toggle">
                <div class="vision-toggle-label">
                    <span class="icon">üëÅÔ∏è</span>
                    <span>Continuous Watching</span>
                </div>
                <label class="toggle-switch">
                    <input type="checkbox" id="visionToggle" onchange="toggleVisualAwareness()">
                    <span class="toggle-slider"></span>
                </label>
            </div>
            
            <!-- Vision Status -->
            <div class="vision-status not-watching" id="visionStatus">
                <span class="icon">‚è∏Ô∏è</span>
                <span id="visionStatusText">Not watching</span>
            </div>
            
            <div class="camera-container">
                <video id="cameraPreview" autoplay playsinline muted width="640" height="480"></video>
                <canvas id="cameraCanvas" style="display: none;"></canvas>
                <div class="camera-overlay" id="cameraOverlay">
                    <!-- Face boxes will be drawn here dynamically -->
                </div>
            </div>
            <div class="camera-status" id="cameraStatus">Camera initializing...</div>
            <div class="camera-controls">
                <button class="camera-action-btn" onclick="captureAndIdentify()" id="identifyBtn">
                    üîç Who Am I?
                </button>
                <button class="camera-action-btn learn-btn" onclick="captureAndLearn()" id="learnBtn">
                    üß† Learn My Face
                </button>
            </div>
            <div class="known-faces" id="knownFaces">
                <h4>Known Faces:</h4>
                <div id="knownFacesList">Loading...</div>
            </div>
        </div>
    </div>
    
    <!-- RICH DISPLAY PANEL -->
    <div class="rich-display" id="richDisplay">
        <div class="rich-display-header">
            <span class="rich-display-title">üìÑ Full Response</span>
            <button class="rich-display-toggle" onclick="toggleRichDisplay()">‚ñº</button>
        </div>
        <div class="rich-display-content" id="richDisplayContent">
            <!-- Rich content items rendered here -->
        </div>
    </div>

    <script>
        // ============ CONFIG ============
        // API base URL - empty string means same origin (works for both localhost and network access)
        const API_BASE = '';
        
        // ============ STATE ============
        let isRecording = false;
        let wantsToRecord = false;  // User's intent to keep recording (toggle state)
        let hotMicEnabled = false;  // Hot mic mode (always listening)
        let isMuted = false;
        let isBusy = false;
        let recognition = null;
        let audioContext = null;
        let analyser = null;
        let mediaStream = null;
        let animationFrameId = null;
        let currentDisplayContent = null;
        let richDisplayOpen = false;
        let audioUnlocked = false;  // Mobile audio requires user interaction first
        let audioPlayer = null;
        
        // Mic Settings State
        let selectedMicDeviceId = localStorage.getItem('selectedMicDeviceId') || null;
        let micTestStream = null;
        let micTestAnalyser = null;
        let micTestAnimationId = null;
        
        // Visual Awareness State
        let visualAwarenessActive = false;  // Continuous watching mode
        let visionInterval = null;          // Frame analysis interval
        let cameraStream = null;            // Camera stream reference
        let lastSeenPeople = [];            // Track who was visible
        let visualContext = '';             // Current visual context for Abby
        
        // ============ MOBILE AUDIO UNLOCK ============
        // Mobile browsers require a user interaction before audio can play
        async function unlockAudio() {
            if (audioUnlocked) return true;
            
            try {
                // Create a silent audio context to unlock audio
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const buffer = ctx.createBuffer(1, 1, 22050);
                const source = ctx.createBufferSource();
                source.buffer = buffer;
                source.connect(ctx.destination);
                source.start(0);
                
                // Also try playing a tiny silent audio
                const silentAudio = new Audio('data:audio/mp3;base64,SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU4Ljc2LjEwMAAAAAAAAAAAAAAA/+M4wAAAAAAAAAAAAEluZm8AAAAPAAAAAwAAAbAAqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV//////////////////////////////////////////////////////////////////8AAAAATGF2YzU4LjEzAAAAAAAAAAAAAAAAJAAAAAAAAAAAAbD///////8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/+MYxAALkAJQ+UMQAgAAA0gAAABU/+MYxA0L+CpBkZGQAAAADSAAAAFU');
                await silentAudio.play().catch(() => {});
                
                audioUnlocked = true;
                console.log('üîä Audio unlocked for mobile playback');
                return true;
            } catch (e) {
                console.warn('Could not unlock audio:', e);
                return false;
            }
        }
        
        // ============ MIC SETTINGS ============
        async function openMicSettings() {
            const modal = document.getElementById('micSettingsModal');
            modal.classList.add('active');
            
            // Enumerate audio devices
            await enumerateMicDevices();
            
            // Start mic level testing
            startMicLevelTest();
        }
        
        function closeMicSettings() {
            const modal = document.getElementById('micSettingsModal');
            modal.classList.remove('active');
            
            // Stop mic test
            stopMicLevelTest();
        }
        
        async function enumerateMicDevices() {
            const listEl = document.getElementById('micDeviceList');
            
            try {
                // First request mic permission to get device labels
                await navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => stream.getTracks().forEach(t => t.stop()));
                
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputs = devices.filter(d => d.kind === 'audioinput');
                
                if (audioInputs.length === 0) {
                    listEl.innerHTML = '<div style="color: var(--error); padding: 1rem; text-align: center;">No microphones found</div>';
                    return;
                }
                
                listEl.innerHTML = audioInputs.map((device, i) => {
                    const isSelected = selectedMicDeviceId === device.deviceId || 
                        (!selectedMicDeviceId && device.deviceId === 'default');
                    const label = device.label || `Microphone ${i + 1}`;
                    const shortId = device.deviceId.substring(0, 8) + '...';
                    
                    return `
                        <div class="mic-device-option ${isSelected ? 'selected' : ''}" 
                             data-device-id="${device.deviceId}"
                             onclick="selectMicDevice(this, '${device.deviceId}')">
                            <span class="device-icon">${i === 0 ? 'üéôÔ∏è' : 'üé§'}</span>
                            <div class="device-info">
                                <div class="device-name">${escapeHtml(label)}</div>
                                <div class="device-id">${shortId}</div>
                            </div>
                        </div>
                    `;
                }).join('');
                
            } catch (e) {
                console.error('Failed to enumerate mic devices:', e);
                listEl.innerHTML = `
                    <div style="color: var(--error); padding: 1rem; text-align: center;">
                        Failed to access microphones<br>
                        <small style="color: var(--text-muted)">${e.message}</small>
                    </div>
                `;
            }
        }
        
        function selectMicDevice(element, deviceId) {
            // Update UI
            document.querySelectorAll('.mic-device-option').forEach(el => el.classList.remove('selected'));
            element.classList.add('selected');
            
            // Update selection (not saved until Apply)
            element.dataset.pendingSelection = deviceId;
            
            // Restart level test with new device
            startMicLevelTest(deviceId);
        }
        
        async function startMicLevelTest(deviceId = null) {
            stopMicLevelTest();
            
            const targetDeviceId = deviceId || selectedMicDeviceId;
            const constraints = targetDeviceId ? 
                { audio: { deviceId: { exact: targetDeviceId } } } : 
                { audio: true };
            
            try {
                micTestStream = await navigator.mediaDevices.getUserMedia(constraints);
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                micTestAnalyser = audioContext.createAnalyser();
                micTestAnalyser.fftSize = 256;
                
                const source = audioContext.createMediaStreamSource(micTestStream);
                source.connect(micTestAnalyser);
                
                const dataArray = new Uint8Array(micTestAnalyser.frequencyBinCount);
                const levelFill = document.getElementById('micLevelFill');
                
                function updateLevel() {
                    micTestAnimationId = requestAnimationFrame(updateLevel);
                    micTestAnalyser.getByteFrequencyData(dataArray);
                    
                    const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
                    const level = Math.min(100, (average / 128) * 100);
                    levelFill.style.width = level + '%';
                }
                
                updateLevel();
            } catch (e) {
                console.error('Mic test failed:', e);
            }
        }
        
        function stopMicLevelTest() {
            if (micTestAnimationId) {
                cancelAnimationFrame(micTestAnimationId);
                micTestAnimationId = null;
            }
            if (micTestStream) {
                micTestStream.getTracks().forEach(t => t.stop());
                micTestStream = null;
            }
            micTestAnalyser = null;
        }
        
        function applyMicSettings() {
            // Get the selected device
            const selectedEl = document.querySelector('.mic-device-option.selected');
            if (selectedEl) {
                selectedMicDeviceId = selectedEl.dataset.deviceId;
                localStorage.setItem('selectedMicDeviceId', selectedMicDeviceId);
                console.log('üé§ Mic device set to:', selectedMicDeviceId);
                
                // Reinitialize audio visualization with new device
                if (mediaStream) {
                    mediaStream.getTracks().forEach(t => t.stop());
                    startAudioVisualization();
                }
            }
            
            closeMicSettings();
        }

        // ============ INITIALIZATION ============
        document.addEventListener('DOMContentLoaded', () => {
            // Check for HTTPS requirement on mobile
            const isSecure = location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1';
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            
            if (isMobile && !isSecure) {
                console.warn('‚ö†Ô∏è Mobile device on non-HTTPS connection - mic may not work');
                // Show warning in console but don't block - some browsers still allow it on local network
            }
            
            initSpeechRecognition();
            createVisualizerBars();
            checkHealth();
            setInterval(checkHealth, 15000);
            
            // Start logs auto-refresh if panel is open
            setInterval(() => {
                if (document.getElementById('logsPanel').classList.contains('active')) {
                    refreshLogs();
                }
            }, 3000);
            
            document.getElementById('textInput').addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    sendTextMessage();
                }
            });
        });
        
        function initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.warn('Speech Recognition not supported');
                // Update UI to show text-only mode
                const transcriptText = document.getElementById('transcriptText');
                if (transcriptText) {
                    transcriptText.textContent = '‚ö†Ô∏è Voice not supported - use text chat or try Chrome';
                }
                // Show a more visible warning on mobile
                const voiceStatus = document.getElementById('voiceStatus');
                if (voiceStatus) {
                    voiceStatus.textContent = '‚ùå Voice N/A';
                    voiceStatus.style.color = '#ef4444';
                }
                return;
            }
            
            console.log('üé§ Initializing Web Speech API...');
            
            recognition = new SpeechRecognition();
            recognition.continuous = true;  // Keep listening until user toggles off
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            recognition.maxAlternatives = 1;
            
            recognition.onstart = () => {
                isRecording = true;
                console.log('üé§ Speech recognition started successfully');
                
                // Clear the timeout since onstart fired
                if (recognition._startTimeout) {
                    clearTimeout(recognition._startTimeout);
                    recognition._startTimeout = null;
                }
                
                updateVoiceUI('listening');
                document.getElementById('transcriptText').textContent = 'üé§ Mic is ON - speak now!';
                document.getElementById('voiceStatus').textContent = 'üé§ Listening...';
            };
            
            // This fires when audio actually starts being captured
            recognition.onaudiostart = () => {
                console.log('üîä Audio capture started - mic is receiving sound');
                document.getElementById('voiceStatus').textContent = 'üé§ Listening...';
                
                // NOW it's safe to start visualization - speech recognition has the mic
                // Visualization will share the audio stream
                startAudioVisualization().catch(e => {
                    console.warn('Visualization unavailable:', e);
                });
            };
            
            recognition.onspeechstart = () => {
                console.log('üó£Ô∏è Speech detected!');
                document.getElementById('voiceStatus').textContent = 'üó£Ô∏è Hearing speech...';
                
                // Natural interrupt: if Abby is speaking/thinking and user starts talking, interrupt her
                notifyUserSpeaking();
            };
            
            recognition.onresult = (event) => {
                let interim = '';
                let final = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        final += transcript;
                    } else {
                        interim += transcript;
                    }
                }
                
                const transcriptText = document.getElementById('transcriptText');
                const statusEl = document.getElementById('voiceStatus');
                
                if (final) {
                    console.log('üé§ Final transcript:', final);
                    transcriptText.textContent = '‚úÖ "' + final + '"';
                    transcriptText.classList.remove('interim');
                    statusEl.textContent = '‚úÖ Heard you!';
                    // Stop recording while processing, then auto-resume if toggle is on
                    if (wantsToRecord) {
                        recognition.stop();
                    }
                    processVoiceInput(final);
                } else if (interim) {
                    // Show they're being heard with green text
                    transcriptText.textContent = 'üé§ "' + interim + '..."';
                    transcriptText.classList.add('interim');
                    statusEl.textContent = 'üëÇ Hearing you...';
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                isRecording = false;
                
                let errorMsg = 'Speech error: ' + event.error;
                switch (event.error) {
                    case 'not-allowed':
                        errorMsg = 'üö´ Mic blocked. In browser settings, allow microphone for this site.';
                        break;
                    case 'no-speech':
                        // This is normal - just means silence detected
                        if (wantsToRecord || hotMicEnabled) {
                            // Quietly retry
                            setTimeout(() => {
                                if ((wantsToRecord || hotMicEnabled) && !isBusy) {
                                    try { recognition.start(); } catch(e) {}
                                }
                            }, 100);
                            return;
                        }
                        errorMsg = 'üîá No speech heard. Tap mic and speak.';
                        break;
                    case 'network':
                        errorMsg = 'üåê Network error. Check connection.';
                        break;
                    case 'audio-capture':
                        errorMsg = 'üé§ No microphone found.';
                        break;
                    case 'aborted':
                        errorMsg = 'Listening stopped.';
                        break;
                }
                
                document.getElementById('transcriptText').textContent = errorMsg;
                updateVoiceUI('error');
                setTimeout(() => updateVoiceUI('ready'), 3000);
            };
            
            recognition.onend = () => {
                isRecording = false;
                stopAudioVisualization();
                
                // Auto-restart if toggle is still on and not busy
                if (wantsToRecord && !isBusy) {
                    setTimeout(() => {
                        if (wantsToRecord && !isBusy && !isRecording) {
                            try {
                                recognition.start();
                                // Don't start visualization here - onaudiostart will do it
                            } catch (e) {
                                console.warn('Could not restart recognition:', e);
                            }
                        }
                    }, 100);
                } else if (!isBusy) {
                    updateVoiceUI('ready');
                }
            };
        }
        
        function createVisualizerBars() {
            const visualizer = document.getElementById('audioVisualizer');
            for (let i = 0; i < 12; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                bar.style.height = '4px';
                visualizer.appendChild(bar);
            }
        }
        
        // ============ HEALTH CHECK ============
        let redirectOffered = false;  // Only offer redirect once per session
        
        async function checkHealth() {
            try {
                const response = await fetch('/api/health');
                const data = await response.json();
                const dot = document.getElementById('statusDot');
                dot.classList.toggle('offline', data.status !== 'healthy');
                
                // Update ngrok status from health check
                if (data.ngrok) {
                    updateNgrokUI(data.ngrok);
                }
                
                // Auto-redirect suggestion for mobile (only offer once)
                if (data.suggest_redirect && !redirectOffered && data.is_mobile) {
                    redirectOffered = true;
                    offerMobileRedirect(data.suggest_redirect);
                }
            } catch {
                document.getElementById('statusDot').classList.add('offline');
            }
        }
        
        function offerMobileRedirect(ngrokUrl) {
            // Create a nice modal/banner for mobile users
            const banner = document.createElement('div');
            banner.id = 'mobileRedirectBanner';
            banner.style.cssText = `
                position: fixed;
                top: 0;
                left: 0;
                right: 0;
                background: linear-gradient(135deg, #6366f1, #8b5cf6);
                color: white;
                padding: 1rem;
                z-index: 9999;
                text-align: center;
                box-shadow: 0 4px 20px rgba(0,0,0,0.3);
            `;
            banner.innerHTML = `
                <div style="margin-bottom: 0.5rem; font-weight: 600;">üì± Mobile Detected!</div>
                <div style="font-size: 0.85rem; margin-bottom: 0.75rem;">
                    For camera & mic access, switch to secure connection
                </div>
                <div style="display: flex; gap: 0.5rem; justify-content: center;">
                    <button onclick="window.location.href='${ngrokUrl}'" style="
                        background: white;
                        color: #6366f1;
                        border: none;
                        padding: 0.5rem 1rem;
                        border-radius: 0.5rem;
                        font-weight: 600;
                        cursor: pointer;
                    ">üîí Switch to HTTPS</button>
                    <button onclick="this.parentElement.parentElement.remove()" style="
                        background: rgba(255,255,255,0.2);
                        color: white;
                        border: none;
                        padding: 0.5rem 1rem;
                        border-radius: 0.5rem;
                        cursor: pointer;
                    ">Stay Here</button>
                </div>
            `;
            document.body.prepend(banner);
            
            console.log('üì± Ngrok auto-started for mobile! URL:', ngrokUrl);
        }
        
        // ============ LOGS PANEL ============
        function toggleLogs() {
            const panel = document.getElementById('logsPanel');
            const btn = document.getElementById('logsToggle');
            
            if (panel.classList.toggle('active')) {
                btn.classList.add('active');
                refreshLogs();
            } else {
                btn.classList.remove('active');
            }
        }
        
        async function refreshLogs() {
            try {
                const response = await fetch('/api/logs');
                const data = await response.json();
                const container = document.getElementById('logsContent');
                
                if (data.logs && data.logs.length > 0) {
                    container.innerHTML = data.logs.map(log => `
                        <div class="log-entry">
                            <span class="log-time">${log.time}</span>
                            <span class="log-level ${log.level}">${log.level}</span>
                            <span class="log-message">${escapeHtml(log.message)}</span>
                        </div>
                    `).join('');
                    
                    // Auto-scroll to bottom
                    container.scrollTop = container.scrollHeight;
                } else {
                    container.innerHTML = '<div class="log-entry"><span class="log-message" style="color: var(--text-muted)">No logs yet...</span></div>';
                }
            } catch (e) {
                console.error('Failed to fetch logs:', e);
            }
        }
        
        async function clearLogs() {
            try {
                await fetch('/api/logs/clear', { method: 'POST' });
                refreshLogs();
            } catch (e) {
                console.error('Failed to clear logs:', e);
            }
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        // ============ NGROK CONTROL ============
        async function toggleNgrok() {
            const btn = document.getElementById('ngrokToggle');
            const statusEl = document.getElementById('ngrokStatus');
            
            // Check current status
            try {
                const statusResponse = await fetch('/api/ngrok/status');
                const status = await statusResponse.json();
                
                if (status.running) {
                    // Stop ngrok
                    btn.textContent = '‚è≥ Stopping...';
                    btn.disabled = true;
                    
                    const stopResponse = await fetch('/api/ngrok/stop', { method: 'POST' });
                    const result = await stopResponse.json();
                    
                    btn.disabled = false;
                    updateNgrokUI({ running: false });
                } else {
                    // Start ngrok
                    btn.textContent = '‚è≥ Starting...';
                    btn.disabled = true;
                    
                    const startResponse = await fetch('/api/ngrok/start', { method: 'POST' });
                    const result = await startResponse.json();
                    
                    btn.disabled = false;
                    
                    if (result.success) {
                        updateNgrokUI({ running: true, url: result.url });
                    } else {
                        alert('Failed to start ngrok: ' + (result.error || 'Unknown error'));
                        updateNgrokUI({ running: false });
                    }
                }
            } catch (e) {
                console.error('Ngrok toggle error:', e);
                btn.disabled = false;
                btn.textContent = 'üåê Ngrok';
            }
        }
        
        function updateNgrokUI(status) {
            const btn = document.getElementById('ngrokToggle');
            const statusText = document.getElementById('ngrokStatusText');
            const urlEl = document.getElementById('ngrokUrl');
            const statusContainer = document.getElementById('ngrokStatus');
            
            if (status.running) {
                btn.textContent = 'üåê Stop Ngrok';
                btn.classList.add('active');
                statusText.textContent = 'Connected';
                statusContainer.classList.add('connected');
                
                if (status.url) {
                    urlEl.textContent = status.url;
                    urlEl.style.display = 'inline';
                }
            } else {
                btn.textContent = 'üåê Start Ngrok';
                btn.classList.remove('active');
                statusText.textContent = 'Disconnected';
                statusContainer.classList.remove('connected');
                urlEl.style.display = 'none';
            }
        }
        
        function copyNgrokUrl() {
            const url = document.getElementById('ngrokUrl').textContent;
            if (url) {
                navigator.clipboard.writeText(url).then(() => {
                    const urlEl = document.getElementById('ngrokUrl');
                    const originalText = urlEl.textContent;
                    urlEl.textContent = '‚úì Copied!';
                    setTimeout(() => urlEl.textContent = originalText, 1500);
                });
            }
        }

        // ============ TEXT CHAT ============
        let currentStreamingMessage = null;  // Reference to the message being streamed
        let useStreaming = true;  // Toggle for streaming vs non-streaming mode
        
        function addMessage(content, role = 'assistant', isStreaming = false) {
            const messages = document.getElementById('messages');
            const div = document.createElement('div');
            div.className = `msg ${role}`;
            if (isStreaming) div.classList.add('streaming');
            
            const avatar = document.createElement('div');
            avatar.className = 'avatar';
            avatar.textContent = role === 'user' ? 'U' : 'A';
            
            const contentDiv = document.createElement('div');
            contentDiv.className = 'content';
            contentDiv.textContent = content;
            
            div.appendChild(avatar);
            div.appendChild(contentDiv);
            messages.appendChild(div);
            messages.scrollTop = messages.scrollHeight;
            
            return contentDiv;  // Return content div for streaming updates
        }
        
        function addThinkingMessage() {
            const messages = document.getElementById('messages');
            const div = document.createElement('div');
            div.className = 'msg thinking';
            div.id = 'thinkingMsg';
            
            const avatar = document.createElement('div');
            avatar.className = 'avatar';
            avatar.textContent = 'üí≠';
            
            const contentDiv = document.createElement('div');
            contentDiv.className = 'content';
            contentDiv.innerHTML = '<div class="typing-indicator"><span></span><span></span><span></span></div>';
            
            div.appendChild(avatar);
            div.appendChild(contentDiv);
            messages.appendChild(div);
            messages.scrollTop = messages.scrollHeight;
            
            return contentDiv;
        }
        
        function removeThinkingMessage() {
            const thinking = document.getElementById('thinkingMsg');
            if (thinking) thinking.remove();
        }
        
        function showInterruptButton(show) {
            const btn = document.getElementById('interruptBtn');
            if (show) {
                btn.classList.add('visible');
            } else {
                btn.classList.remove('visible');
            }
        }
        
        async function interruptAbby() {
            try {
                await fetch('/api/stream/interrupt', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({})
                });
                showInterruptButton(false);
            } catch (e) {
                console.error('Interrupt failed:', e);
            }
        }
        
        // Notify backend that user started speaking (for natural interrupts)
        async function notifyUserSpeaking() {
            try {
                await fetch('/api/stream/user-speaking', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({})
                });
            } catch (e) {
                // Silently ignore - not critical
            }
        }
        
        async function sendTextMessage() {
            if (isBusy) return;
            
            const input = document.getElementById('textInput');
            const text = input.value.trim();
            if (!text) return;
            
            addMessage(text, 'user');
            input.value = '';
            isBusy = true;
            document.getElementById('sendBtn').disabled = true;
            
            if (useStreaming) {
                await sendStreamingMessage(text);
            } else {
                await sendNonStreamingMessage(text);
            }
        }
        
        async function sendStreamingMessage(text) {
            const thinkingContent = addThinkingMessage();
            showInterruptButton(true);
            
            try {
                const payload = { message: text };
                if (currentSession?.session_id) {
                    payload.session_id = currentSession.session_id;
                }
                if (visualAwarenessActive && visualContext) {
                    payload.visual_context = visualContext;
                }
                
                const response = await fetch('/api/stream/chat', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}`);
                }
                
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let fullResponse = '';
                let responseContent = null;
                
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    
                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');
                    
                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            try {
                                const event = JSON.parse(line.slice(6));
                                
                                switch (event.type) {
                                    case 'thinking':
                                        thinkingContent.textContent = 'üí≠ ' + event.content;
                                        break;
                                    
                                    case 'text':
                                        if (!responseContent) {
                                            removeThinkingMessage();
                                            responseContent = addMessage('', 'assistant', true);
                                        }
                                        if (event.metadata?.partial) {
                                            fullResponse += event.content;
                                            responseContent.textContent = fullResponse;
                                        }
                                        break;
                                    
                                    case 'step':
                                        const stepDiv = document.createElement('div');
                                        stepDiv.className = `step-indicator ${event.metadata?.status || ''}`;
                                        stepDiv.textContent = event.content;
                                        if (responseContent) {
                                            responseContent.appendChild(stepDiv);
                                        } else {
                                            thinkingContent.appendChild(stepDiv);
                                        }
                                        break;
                                    
                                    case 'plan':
                                        thinkingContent.innerHTML = 'üìã ' + event.content;
                                        if (event.metadata?.steps) {
                                            const stepsHtml = event.metadata.steps.map((s, i) => 
                                                `<div class="step-indicator">${i+1}. ${s}</div>`
                                            ).join('');
                                            thinkingContent.innerHTML += stepsHtml;
                                        }
                                        break;
                                    
                                    case 'done':
                                        removeThinkingMessage();
                                        showInterruptButton(false);
                                        if (!responseContent && fullResponse) {
                                            addMessage(fullResponse, 'assistant');
                                        }
                                        break;
                                    
                                    case 'error':
                                        removeThinkingMessage();
                                        addMessage('‚ùå ' + event.content, 'assistant');
                                        break;
                                    
                                    case 'interrupted':
                                        removeThinkingMessage();
                                        addMessage('‚èπÔ∏è Interrupted', 'assistant');
                                        break;
                                }
                                
                                // Scroll to bottom
                                const messages = document.getElementById('messages');
                                messages.scrollTop = messages.scrollHeight;
                                
                            } catch (e) {
                                // Ignore parse errors from partial chunks
                            }
                        }
                    }
                }
                
            } catch (e) {
                removeThinkingMessage();
                addMessage('‚ùå Error: ' + e.message, 'assistant');
            } finally {
                showInterruptButton(false);
                isBusy = false;
                document.getElementById('sendBtn').disabled = false;
            }
        }
        
        async function sendNonStreamingMessage(text) {
            try {
                // Include session_id for user presence awareness
                const payload = { task: text };
                if (currentSession?.session_id) {
                    payload.session_id = currentSession.session_id;
                }
                
                // Inject visual context if watching (LOCAL processing)
                if (visualAwarenessActive && visualContext) {
                    payload.visual_context = visualContext;
                    console.log('üëÅÔ∏è Injecting visual context into text chat');
                }
                
                const response = await fetch('/api/task', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                addMessage(result.output || result.error || 'Done!', 'assistant');
            } catch (e) {
                addMessage('‚ùå Error: ' + e.message, 'assistant');
            } finally {
                isBusy = false;
                document.getElementById('sendBtn').disabled = false;
            }
        }
        
        // ============ VOICE MODE ============
        async function enterVoiceMode() {
            // Unlock audio on mobile (must happen during user interaction)
            await unlockAudio();
            
            document.getElementById('voiceMode').classList.add('active');
            document.body.style.overflow = 'hidden';
            updateVoiceUI('ready');
            
            // Fetch and display the current model being used
            try {
                const resp = await fetch(`${API_BASE}/api/current_model`);
                if (resp.ok) {
                    const data = await resp.json();
                    document.getElementById('modelBadge').textContent = data.conversation_model || 'mistral:latest';
                }
            } catch (e) {
                console.log('Could not fetch current model:', e);
            }
            
            // Show helpful message on first entry
            const transcriptText = document.getElementById('transcriptText');
            transcriptText.textContent = 'Tap the mic button to start talking';
        }
        
        function exitVoiceMode() {
            document.getElementById('voiceMode').classList.remove('active');
            document.body.style.overflow = '';
            wantsToRecord = false;  // Reset toggle state
            
            // Turn off hot mic if active
            if (hotMicEnabled) {
                hotMicEnabled = false;
                document.getElementById('hotMicBtn').style.background = '';
                document.getElementById('hotMicBtn').style.borderColor = '';
                document.getElementById('hotMicIndicator').classList.remove('active');
            }
            
            // Close rich display
            richDisplayOpen = false;
            document.getElementById('richDisplay').classList.remove('active');
            hideDisplayPreview();
            
            if (isRecording && recognition) {
                recognition.stop();
            }
            // Stop both browser TTS and ElevenLabs audio
            speechSynthesis.cancel();
            if (audioPlayer) {
                audioPlayer.pause();
                audioPlayer = null;
            }
            stopAudioVisualization();
        }
        
        async function toggleRecording() {
            if (!recognition) {
                const msg = 'Speech recognition is not supported in your browser.\n\nTry:\n‚Ä¢ Chrome (desktop or Android)\n‚Ä¢ Safari (iOS/Mac)\n‚Ä¢ Edge\n\nNote: Must use HTTPS or localhost for mic access.';
                alert(msg);
                document.getElementById('transcriptText').textContent = 'Speech not supported - use text chat instead';
                return;
            }
            
            if (isBusy) return;
            
            if (isRecording || wantsToRecord) {
                // Toggle OFF - stop recording
                wantsToRecord = false;
                recognition.stop();
                document.getElementById('transcriptText').textContent = '';
                updateVoiceUI('ready');
            } else {
                // Toggle ON - start recording
                wantsToRecord = true;
                try {
                    // Check if already recording
                    if (isRecording) {
                        console.log('Already recording, no need to start');
                        return;
                    }
                    
                    // Update UI to show we're trying
                    document.getElementById('transcriptText').textContent = 'Starting microphone...';
                    updateVoiceUI('listening');
                    
                    // Set a timeout in case onstart never fires
                    const startTimeout = setTimeout(() => {
                        if (!isRecording && wantsToRecord) {
                            console.warn('Recognition start timeout - onstart never fired');
                            document.getElementById('transcriptText').textContent = '‚ö†Ô∏è Mic may not be working. Try speaking or tap mic again.';
                        }
                    }, 3000);
                    
                    // Store timeout so we can clear it if onstart fires
                    recognition._startTimeout = startTimeout;
                    
                    // Start recognition - visualization will start in onaudiostart callback
                    // DON'T start visualization here - it steals the mic from SpeechRecognition!
                    recognition.start();
                    console.log('recognition.start() called - waiting for onaudiostart...');
                    
                } catch (e) {
                    console.error('Failed to start recognition:', e);
                    isRecording = false;
                    wantsToRecord = false;
                    
                    let errorMsg = 'Error: ' + e.message;
                    if (e.name === 'NotAllowedError' || e.message.includes('not-allowed')) {
                        errorMsg = 'üö´ Mic access denied. Allow microphone in browser settings.';
                    } else if (e.name === 'NotFoundError') {
                        errorMsg = 'üé§ No microphone found. Check your device.';
                    } else if (e.name === 'InvalidStateError') {
                        // Recognition already running - try to stop and restart
                        try {
                            recognition.stop();
                            setTimeout(() => toggleRecording(), 500);
                            return;
                        } catch (stopErr) {
                            errorMsg = 'Voice busy - please wait';
                        }
                    }
                    document.getElementById('transcriptText').textContent = errorMsg;
                    updateVoiceUI('error');
                    setTimeout(() => updateVoiceUI('ready'), 3000);
                }
            }
        }
        
        // ============ HOT MIC MODE ============
        function toggleHotMic() {
            hotMicEnabled = !hotMicEnabled;
            const hotMicBtn = document.getElementById('hotMicBtn');
            const indicator = document.getElementById('hotMicIndicator');
            
            if (hotMicEnabled) {
                hotMicBtn.style.background = 'var(--error)';
                hotMicBtn.style.borderColor = 'var(--error)';
                indicator.classList.add('active');
                
                // Auto-start recording if not already
                if (!wantsToRecord && !isBusy) {
                    toggleRecording();
                }
            } else {
                hotMicBtn.style.background = '';
                hotMicBtn.style.borderColor = '';
                indicator.classList.remove('active');
            }
            
            // Update server settings
            fetch('/api/realtime/settings', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ 
                    hot_mic_enabled: hotMicEnabled,
                    auto_resume: hotMicEnabled
                })
            }).catch(e => console.warn('Could not update hot mic settings:', e));
        }
        
        // ============ RICH DISPLAY ============
        function toggleRichDisplay() {
            richDisplayOpen = !richDisplayOpen;
            const display = document.getElementById('richDisplay');
            display.classList.toggle('active', richDisplayOpen);
        }
        
        function showDisplayPreview(content) {
            const preview = document.getElementById('displayPreview');
            const previewText = document.getElementById('displayPreviewText');
            
            // Show first markdown content as preview
            const markdown = content.find(c => c.type === 'markdown');
            if (markdown) {
                // Strip markdown and truncate
                let text = markdown.content
                    .replace(/```[\s\S]*?```/g, '[code]')
                    .replace(/!\[.*?\]\(.*?\)/g, '[image]')
                    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
                    .replace(/[#*_~`]/g, '')
                    .trim();
                previewText.textContent = text.substring(0, 300) + (text.length > 300 ? '...' : '');
            }
            
            preview.classList.add('active');
            currentDisplayContent = content;
        }
        
        function hideDisplayPreview() {
            document.getElementById('displayPreview').classList.remove('active');
        }
        
        function renderRichContent(content) {
            const container = document.getElementById('richDisplayContent');
            container.innerHTML = '';
            
            content.forEach(item => {
                const div = document.createElement('div');
                div.className = `rich-content-item ${item.type}`;
                
                switch (item.type) {
                    case 'markdown':
                        // Parse out code blocks and render them separately
                        div.innerHTML = renderMarkdownWithCodeBlocks(item.content);
                        break;
                        
                    case 'code':
                        div.innerHTML = `
                            <div class="code-header">
                                <span>${item.language || 'Code'}</span>
                                <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                            </div>
                            <pre><code>${escapeHtml(item.content)}</code></pre>
                        `;
                        break;
                        
                    case 'image':
                        div.innerHTML = `<img src="${item.content}" alt="${item.alt_text || 'Image'}" loading="lazy">`;
                        break;
                        
                    case 'video':
                        div.innerHTML = `<iframe src="${item.content}" allowfullscreen></iframe>`;
                        break;
                        
                    case 'link':
                        div.innerHTML = `<a href="${item.content}" target="_blank">üîó ${item.title || item.content}</a>`;
                        break;
                }
                
                container.appendChild(div);
            });
        }
        
        function renderMarkdownWithCodeBlocks(text) {
            // First, extract and replace code blocks with placeholders
            const codeBlocks = [];
            let processed = text.replace(/```(\w*)\n?([\s\S]*?)```/g, (match, lang, code) => {
                const index = codeBlocks.length;
                codeBlocks.push({ lang: lang || 'code', code: code.trim() });
                return `__CODE_BLOCK_${index}__`;
            });
            
            // Render basic markdown
            processed = processed
                .replace(/`([^`]+)`/g, '<code class="inline-code">$1</code>')
                .replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>')
                .replace(/\*([^*]+)\*/g, '<em>$1</em>')
                .replace(/^### (.+)$/gm, '<h3>$1</h3>')
                .replace(/^## (.+)$/gm, '<h2>$1</h2>')
                .replace(/^# (.+)$/gm, '<h1>$1</h1>')
                .replace(/^- (.+)$/gm, '<li>$1</li>')
                .replace(/(<li>.*<\/li>)/s, '<ul>$1</ul>')
                .replace(/\n\n/g, '</p><p>')
                .replace(/\n/g, '<br>');
            
            // Wrap in paragraph
            processed = '<p>' + processed + '</p>';
            
            // Now replace placeholders with rendered code blocks
            codeBlocks.forEach((block, index) => {
                const codeHtml = `
                    <div class="code-block">
                        <div class="code-header">
                            <span>${block.lang}</span>
                            <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                        </div>
                        <pre><code>${escapeHtml(block.code)}</code></pre>
                    </div>
                `;
                processed = processed.replace(`__CODE_BLOCK_${index}__`, codeHtml);
            });
            
            return processed;
        }
        
        function renderMarkdown(text) {
            // Simple markdown rendering (legacy, use renderMarkdownWithCodeBlocks for full support)
            return renderMarkdownWithCodeBlocks(text);
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        function copyCode(btn) {
            const code = btn.closest('.rich-content-item').querySelector('code').textContent;
            navigator.clipboard.writeText(code).then(() => {
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        async function processVoiceInput(text) {
            console.log('üìù processVoiceInput called with:', text);
            isBusy = true;
            updateVoiceUI('thinking');
            hideDisplayPreview();
            document.getElementById('transcriptText').textContent = 'ü§î Thinking...';
            
            try {
                // Build payload with session for presence awareness
                const payload = { transcript: text, speak: true };
                if (currentSession?.session_id) {
                    payload.session_id = currentSession.session_id;
                }
                
                // Inject visual context if watching (LOCAL processing)
                if (visualAwarenessActive && visualContext) {
                    payload.visual_context = visualContext;
                    console.log('üëÅÔ∏è Injecting visual context:', visualContext);
                }
                
                console.log('üì§ Sending to API:', payload);
                
                // Use realtime conversation API for rich content
                const response = await fetch('/api/realtime/conversation', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                
                console.log('üì• API Response:', { 
                    hasError: !!result.error,
                    hasVoiceAudio: !!result.voice_audio,
                    voiceAudioLen: result.voice_audio?.length || 0,
                    voiceText: result.voice_text?.substring(0, 50)
                });
                
                if (result.error) {
                    throw new Error(result.error);
                }
                
                // Add to chat history
                addMessage(text, 'user');
                addMessage(result.full_text || result.voice_text, 'assistant');
                
                // Show rich display content
                if (result.display_content && result.display_content.length > 0) {
                    renderRichContent(result.display_content);
                    showDisplayPreview(result.display_content);
                }
                
                // Speak the voice summary (shorter than full text)
                const voiceText = result.voice_text || result.full_text;
                document.getElementById('transcriptText').textContent = 'üîä Playing response...';
                
                if (result.voice_audio) {
                    console.log('üîä Playing pre-synthesized audio...');
                    // Use pre-synthesized audio
                    await playBase64Audio(result.voice_audio);
                    console.log('üîä Audio finished');
                } else {
                    console.log('üîä No voice_audio, using fallback...');
                    // Fallback to synthesizing
                    await speakResponse(voiceText);
                }
                
            } catch (e) {
                console.error('API Error:', e);
                await speakResponse('Sorry, I encountered an error processing your request.');
            } finally {
                isBusy = false;
                
                // Notify server speaking complete (for hot mic auto-resume)
                if (hotMicEnabled) {
                    fetch('/api/realtime/speaking-complete', { method: 'POST' })
                        .catch(e => console.warn('Could not notify speaking complete:', e));
                }
                
                // Resume listening if toggle is still on
                if (wantsToRecord || hotMicEnabled) {
                    updateVoiceUI('listening');
                    try {
                        if (!isRecording) {
                            recognition.start();
                            // Don't start visualization here - onaudiostart will do it
                        }
                    } catch (err) {
                        console.warn('Could not resume recording:', err);
                        updateVoiceUI('ready');
                    }
                } else {
                    updateVoiceUI('ready');
                }
            }
        }
        
        async function playBase64Audio(base64Data) {
            return new Promise(async (resolve, reject) => {
                try {
                    // Ensure audio is unlocked on mobile
                    if (!audioUnlocked) {
                        await unlockAudio();
                    }
                    
                    updateVoiceUI('speaking');
                    
                    const audio = new Audio('data:audio/mp3;base64,' + base64Data);
                    audioPlayer = audio;
                    
                    audio.onended = () => {
                        audioPlayer = null;
                        console.log('üîä Audio playback completed');
                        resolve();
                    };
                    
                    audio.onerror = (e) => {
                        audioPlayer = null;
                        console.error('üîä Audio playback error:', e);
                        reject(e);
                    };
                    
                    if (!isMuted) {
                        try {
                            await audio.play();
                            console.log('üîä Audio playing...');
                        } catch (playError) {
                            console.error('üîä Audio play() failed:', playError);
                            // On mobile, might need user interaction - show message
                            document.getElementById('transcriptText').textContent = 'Tap anywhere to enable audio';
                            resolve();  // Don't fail the whole flow
                        }
                    } else {
                        resolve();
                    }
                } catch (e) {
                    console.error('üîä Audio error:', e);
                    reject(e);
                }
            });
        }
        
        // ============ ELEVENLABS TEXT-TO-SPEECH ============
        let useElevenLabs = true;  // Set to false to use browser TTS
        let elevenLabsConfigured = false;
        
        // ============ DEBUG TEST FUNCTIONS ============
        // Call these from browser console (F12) to test individual components
        window.testMic = function() {
            console.log('üß™ Testing microphone...');
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.log('‚ùå SpeechRecognition API not available in this browser');
                return 'Speech Recognition not supported - try Chrome on desktop/Android or Safari on iOS';
            }
            const sr = new SpeechRecognition();
            sr.onstart = () => console.log('‚úÖ Mic started');
            sr.onaudiostart = () => console.log('‚úÖ Audio capture working');
            sr.onspeechstart = () => console.log('‚úÖ Speech detected!');
            sr.onresult = (e) => console.log('‚úÖ Got result:', e.results[0][0].transcript);
            sr.onerror = (e) => console.log('‚ùå Mic error:', e.error, e);
            sr.onend = () => console.log('üõë Mic stopped');
            sr.start();
            setTimeout(() => sr.stop(), 5000);
            return 'Listening for 5 seconds... speak now!';
        };
        
        // Send text from voice mode fallback input
        async function sendVoiceText() {
            const input = document.getElementById('voiceTextInput');
            const text = input.value.trim();
            if (!text) return;
            
            input.value = '';
            document.getElementById('transcriptText').textContent = '‚úÖ "' + text + '"';
            await processVoiceInput(text);
        }
        
        // Enter key support for voice text input
        document.addEventListener('DOMContentLoaded', () => {
            const voiceTextInput = document.getElementById('voiceTextInput');
            if (voiceTextInput) {
                voiceTextInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter') {
                        e.preventDefault();
                        sendVoiceText();
                    }
                });
            }
        });

        window.testAPI = async function() {
            console.log('üß™ Testing API...');
            const r = await fetch('/api/realtime/conversation', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ transcript: 'Test message', speak: true })
            });
            const data = await r.json();
            console.log('‚úÖ API responded:', data);
            return data;
        };
        
        window.testAudioDirect = async function() {
            console.log('üß™ Testing audio playback...');
            const r = await fetch('/api/realtime/conversation', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ transcript: 'Say hello', speak: true })
            });
            const data = await r.json();
            if (data.voice_audio) {
                console.log('‚úÖ Got audio, length:', data.voice_audio.length);
                const audio = new Audio('data:audio/mp3;base64,' + data.voice_audio);
                audio.volume = 1.0;
                console.log('Audio element created, volume:', audio.volume);
                audio.oncanplay = () => console.log('‚úÖ Audio can play');
                audio.onplay = () => console.log('‚úÖ Audio started playing');
                audio.onended = () => console.log('‚úÖ Audio finished playing');
                audio.onerror = (e) => console.log('‚ùå Audio error:', e, audio.error);
                try {
                    await audio.play();
                    console.log('‚úÖ play() succeeded');
                    return 'Playing audio...';
                } catch (e) {
                    console.log('‚ùå play() failed:', e.name, e.message);
                    return '‚ùå Autoplay blocked: ' + e.message;
                }
            } else {
                return '‚ùå No voice_audio in response';
            }
        };
        
        // Test with a simple beep to isolate audio issues
        window.testBeep = function() {
            console.log('üß™ Testing basic audio with beep...');
            try {
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const oscillator = ctx.createOscillator();
                const gain = ctx.createGain();
                oscillator.connect(gain);
                gain.connect(ctx.destination);
                oscillator.frequency.value = 440;
                gain.gain.value = 0.3;
                oscillator.start();
                setTimeout(() => {
                    oscillator.stop();
                    ctx.close();
                    console.log('‚úÖ Beep finished');
                }, 500);
                return 'üîä You should hear a beep!';
            } catch (e) {
                console.log('‚ùå Beep failed:', e);
                return '‚ùå ' + e.message;
            }
        };
        
        // Test sending a message directly to Abby (bypasses mic)
        window.askAbby = async function(message) {
            message = message || 'Hello Abby, can you hear me?';
            console.log('üß™ Sending to Abby:', message);
            document.getElementById('transcriptText').textContent = 'ü§î Asking Abby: ' + message;
            await processVoiceInput(message);
            return 'Sent!';
        };
        
        console.log('üß™ Debug functions available: testMic(), testAPI(), testAudioDirect(), testBeep(), askAbby("your message")');
        
        // Check ElevenLabs status on load
        async function checkElevenLabsStatus() {
            try {
                const response = await fetch('/api/tts/status');
                const status = await response.json();
                elevenLabsConfigured = status.configured;
                
                if (elevenLabsConfigured) {
                    console.log('‚úÖ ElevenLabs configured - using voice clone');
                    console.log(`   Characters: ${status.characters_used}/${status.characters_limit}`);
                } else {
                    console.log('‚ÑπÔ∏è ElevenLabs not configured - using browser TTS');
                    console.log('   To enable: Set ELEVENLABS_API_KEY and ELEVENLABS_VOICE_ID in .env');
                    useElevenLabs = false;
                }
            } catch (e) {
                console.warn('Could not check ElevenLabs status:', e);
                useElevenLabs = false;
            }
        }
        
        // Initialize on page load
        checkElevenLabsStatus();
        
        async function speakWithElevenLabs(text) {
            return new Promise(async (resolve) => {
                try {
                    updateVoiceUI('speaking');
                    startSpeakingAnimation();
                    
                    // Display what's being spoken
                    document.getElementById('transcriptLabel').textContent = 'Abby says:';
                    document.getElementById('transcriptText').textContent = text;
                    document.getElementById('transcriptText').classList.remove('interim');
                    
                    // Request audio from ElevenLabs API
                    const response = await fetch('/api/tts/synthesize', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ 
                            text: text,
                            settings: {
                                stability: 0.5,
                                similarity_boost: 0.75
                            }
                        })
                    });
                    
                    if (!response.ok) {
                        throw new Error('TTS synthesis failed');
                    }
                    
                    // Get audio blob and play it
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    
                    // Stop any existing audio
                    if (audioPlayer) {
                        audioPlayer.pause();
                        audioPlayer = null;
                    }
                    
                    audioPlayer = new Audio(audioUrl);
                    
                    audioPlayer.onended = () => {
                        stopSpeakingAnimation();
                        URL.revokeObjectURL(audioUrl);
                        resolve();
                    };
                    
                    audioPlayer.onerror = (e) => {
                        console.error('Audio playback error:', e);
                        stopSpeakingAnimation();
                        resolve();
                    };
                    
                    await audioPlayer.play();
                    
                } catch (e) {
                    console.error('ElevenLabs TTS error:', e);
                    stopSpeakingAnimation();
                    // Fall back to browser TTS
                    await speakWithBrowserTTS(text);
                    resolve();
                }
            });
        }
        
        function speakWithBrowserTTS(text) {
            return new Promise((resolve) => {
                if (!window.speechSynthesis) {
                    resolve();
                    return;
                }
                
                speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                
                // Try to find a good voice
                const voices = speechSynthesis.getVoices();
                const preferredVoice = voices.find(v => 
                    v.name.includes('Samantha') || 
                    v.name.includes('Google US English') ||
                    v.name.includes('Microsoft Zira') ||
                    (v.lang === 'en-US' && v.localService)
                );
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                }
                
                utterance.onstart = () => {
                    updateVoiceUI('speaking');
                    startSpeakingAnimation();
                };
                
                utterance.onend = () => {
                    stopSpeakingAnimation();
                    resolve();
                };
                
                utterance.onerror = () => {
                    stopSpeakingAnimation();
                    resolve();
                };
                
                // Display what's being spoken
                document.getElementById('transcriptLabel').textContent = 'Abby says:';
                document.getElementById('transcriptText').textContent = text;
                document.getElementById('transcriptText').classList.remove('interim');
                
                speechSynthesis.speak(utterance);
            });
        }
        
        function speakResponse(text) {
            if (isMuted) {
                return Promise.resolve();
            }
            
            // Use ElevenLabs if configured, otherwise browser TTS
            if (useElevenLabs && elevenLabsConfigured) {
                return speakWithElevenLabs(text);
            } else {
                return speakWithBrowserTTS(text);
            }
        }
        
        // ============ AUDIO VISUALIZATION ============
        async function startAudioVisualization() {
            try {
                // Use selected mic device if set
                const constraints = selectedMicDeviceId ? 
                    { audio: { deviceId: { exact: selectedMicDeviceId } } } : 
                    { audio: true };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 64;
                
                const source = audioContext.createMediaStreamSource(mediaStream);
                source.connect(analyser);
                
                visualize();
                console.log('üé§ Audio visualization started' + (selectedMicDeviceId ? ' with selected device' : ''));
            } catch (e) {
                console.error('Could not access microphone:', e);
            }
        }
        
        function visualize() {
            if (!analyser) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            const bars = document.querySelectorAll('.visualizer-bar');
            
            function draw() {
                animationFrameId = requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                
                // Update visualizer bars
                bars.forEach((bar, i) => {
                    const value = dataArray[i * 2] || 0;
                    const height = Math.max(4, (value / 255) * 20);
                    bar.style.height = height + 'px';
                });
                
                // Update avatar scale based on volume
                const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
                const scale = 1 + (average / 255) * 0.15;
                document.getElementById('mainAvatar').style.setProperty('--speak-scale', scale);
            }
            
            draw();
        }
        
        function stopAudioVisualization() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
                analyser = null;
            }
            
            // Reset visualizer bars
            document.querySelectorAll('.visualizer-bar').forEach(bar => {
                bar.style.height = '4px';
            });
        }
        
        // ============ SPEAKING ANIMATION ============
        let speakingInterval = null;
        
        function startSpeakingAnimation() {
            const avatar = document.getElementById('mainAvatar');
            avatar.classList.add('speaking');
            
            // Simulate audio levels for TTS (since we can't analyze TTS output easily)
            speakingInterval = setInterval(() => {
                const scale = 1 + Math.random() * 0.1;
                avatar.style.setProperty('--speak-scale', scale);
            }, 100);
        }
        
        function stopSpeakingAnimation() {
            const avatar = document.getElementById('mainAvatar');
            avatar.classList.remove('speaking');
            avatar.style.setProperty('--speak-scale', '1');
            
            if (speakingInterval) {
                clearInterval(speakingInterval);
                speakingInterval = null;
            }
        }
        
        // ============ UI UPDATES ============
        function updateVoiceUI(state) {
            const micBtn = document.getElementById('micBtn');
            const statusEl = document.getElementById('voiceStatus');
            const labelEl = document.getElementById('transcriptLabel');
            const thinkingEl = document.getElementById('thinkingIndicator');
            const avatar = document.getElementById('mainAvatar');
            
            micBtn.classList.remove('recording');
            avatar.classList.remove('listening', 'speaking');
            thinkingEl.classList.remove('active');
            micBtn.disabled = false;
            
            switch (state) {
                case 'ready':
                    statusEl.textContent = 'Ready';
                    labelEl.textContent = 'Tap mic to start listening';
                    break;
                case 'listening':
                    statusEl.textContent = 'Listening...';
                    labelEl.textContent = 'Tap mic to stop';
                    micBtn.classList.add('recording');
                    avatar.classList.add('listening');
                    break;
                case 'thinking':
                    statusEl.textContent = 'Processing...';
                    labelEl.textContent = '';
                    thinkingEl.classList.add('active');
                    micBtn.disabled = true;
                    break;
                case 'speaking':
                    statusEl.textContent = 'Speaking...';
                    avatar.classList.add('speaking');
                    micBtn.disabled = true;
                    break;
                case 'error':
                    statusEl.textContent = 'Error';
                    labelEl.textContent = 'Something went wrong. Try again.';
                    break;
            }
        }
        
        function toggleMute() {
            isMuted = !isMuted;
            const muteBtn = document.getElementById('muteBtn');
            muteBtn.textContent = isMuted ? 'üîá' : 'üîä';
            
            if (isMuted) {
                speechSynthesis.cancel();
                if (audioPlayer) {
                    audioPlayer.pause();
                }
            }
        }
        
        // Test audio playback - helps diagnose mobile audio issues
        async function testAudio() {
            const transcriptText = document.getElementById('transcriptText');
            transcriptText.textContent = 'Testing audio...';
            
            try {
                // First unlock audio
                await unlockAudio();
                
                // Try ElevenLabs via the enhanced task endpoint (returns proper base64 JSON)
                if (elevenLabsConfigured) {
                    transcriptText.textContent = 'Requesting test audio from ElevenLabs...';
                    
                    // Use the enhanced/task endpoint which returns proper JSON with base64 audio
                    const response = await fetch(`${API_BASE}/api/enhanced/task`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ 
                            task: 'Say: Hello! Audio test successful. I can hear you!',
                            speak: true
                        })
                    });
                    
                    if (response.ok) {
                        const data = await response.json();
                        if (data.voice_audio) {
                            transcriptText.textContent = 'Playing ElevenLabs audio...';
                            await playBase64Audio(data.voice_audio);
                            transcriptText.textContent = '‚úÖ ElevenLabs audio working! Tap mic to start talking.';
                            return;
                        }
                    }
                    
                    // Fallback: try raw TTS endpoint with blob handling
                    transcriptText.textContent = 'Trying direct TTS...';
                    const ttsResponse = await fetch(`${API_BASE}/api/tts/synthesize`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text: 'Hello! Audio test successful.' })
                    });
                    
                    if (ttsResponse.ok && ttsResponse.headers.get('content-type')?.includes('audio')) {
                        const blob = await ttsResponse.blob();
                        const audioUrl = URL.createObjectURL(blob);
                        const audio = new Audio(audioUrl);
                        audioPlayer = audio;
                        
                        audio.onended = () => {
                            URL.revokeObjectURL(audioUrl);
                            transcriptText.textContent = '‚úÖ Audio working! Tap mic to start talking.';
                        };
                        audio.onerror = () => {
                            transcriptText.textContent = '‚ùå Audio playback failed';
                        };
                        
                        await audio.play();
                        return;
                    }
                }
                
                // Fallback to browser TTS
                transcriptText.textContent = 'Using browser voice...';
                await speakWithBrowserTTS('Audio test. Can you hear me?');
                transcriptText.textContent = '‚úÖ Browser audio working! Tap mic to talk.';
                
            } catch (e) {
                console.error('Audio test failed:', e);
                transcriptText.textContent = '‚ùå Audio failed: ' + e.message;
            }
        }
        
        // Load voices when available
        if (window.speechSynthesis) {
            speechSynthesis.onvoiceschanged = () => {
                speechSynthesis.getVoices();
            };
        }
        
        // ============ CAMERA / FACE RECOGNITION ============
        // cameraStream declared in STATE section above
        let faceRecognitionAvailable = false;
        
        async function checkFaceRecognition() {
            try {
                const response = await fetch('/api/face/status');
                const status = await response.json();
                faceRecognitionAvailable = status.available;
                console.log('Face recognition:', faceRecognitionAvailable ? '‚úÖ Available' : '‚ùå Not available');
                return status;
            } catch (e) {
                console.warn('Could not check face recognition:', e);
                return { available: false };
            }
        }
        
        async function toggleCamera() {
            const modal = document.getElementById('cameraModal');
            if (modal.classList.contains('active')) {
                closeCameraModal();
            } else {
                openCameraModal();
            }
        }
        
        async function openCameraModal() {
            const modal = document.getElementById('cameraModal');
            const video = document.getElementById('cameraPreview');
            const status = document.getElementById('cameraStatus');
            
            modal.classList.add('active');
            status.textContent = 'Starting camera...';
            status.className = 'camera-status';
            
            // Check if camera API is available (requires HTTPS on mobile)
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                const isHTTPS = location.protocol === 'https:';
                const isLocalhost = location.hostname === 'localhost' || location.hostname === '127.0.0.1';
                
                if (!isHTTPS && !isLocalhost) {
                    status.textContent = 'üîí Camera requires HTTPS on mobile. Use localhost or set up HTTPS.';
                } else {
                    status.textContent = '‚ùå Camera not supported in this browser.';
                }
                status.className = 'camera-status error';
                console.error('üì∑ mediaDevices not available. HTTPS:', isHTTPS, 'Localhost:', isLocalhost);
                return;
            }
            
            try {
                // Request camera access
                console.log('üì∑ Requesting camera access...');
                cameraStream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } }
                });
                
                console.log('üì∑ Got camera stream:', cameraStream);
                console.log('üì∑ Video tracks:', cameraStream.getVideoTracks());
                
                video.srcObject = cameraStream;
                
                // Wait for video to be ready
                video.onloadedmetadata = () => {
                    console.log('üì∑ Video metadata loaded:', video.videoWidth, 'x', video.videoHeight);
                };
                
                await video.play();
                console.log('üì∑ Video playing, dimensions:', video.videoWidth, 'x', video.videoHeight);
                
                status.textContent = 'üì∑ Camera ready! Let Abby see you.';
                status.className = 'camera-status success';
                
                // Load known faces
                loadKnownFaces();
                
                // Check face recognition availability
                const faceStatus = await checkFaceRecognition();
                if (!faceStatus.available) {
                    status.textContent = '‚ö†Ô∏è Face recognition not installed on server. Camera works but recognition disabled.';
                    status.className = 'camera-status';
                }
                
            } catch (e) {
                console.error('Camera error:', e);
                status.textContent = '‚ùå ' + (e.name === 'NotAllowedError' ? 
                    'Camera access denied. Allow camera in browser settings.' : 
                    'Camera error: ' + e.message);
                status.className = 'camera-status error';
            }
        }
        
        function closeCameraModal() {
            const modal = document.getElementById('cameraModal');
            modal.classList.remove('active');
            
            // If visual awareness is active, keep camera running in background
            if (visualAwarenessActive) {
                console.log('üì∑ Camera modal closed but visual awareness continues');
                return;  // Don't stop the camera
            }
            
            // Stop camera only if not watching
            if (cameraStream) {
                cameraStream.getTracks().forEach(track => track.stop());
                cameraStream = null;
            }
            
            // Clear face boxes
            const overlay = document.getElementById('cameraOverlay');
            if (overlay) overlay.innerHTML = '';
        }
        
        function captureFrame() {
            const video = document.getElementById('cameraPreview');
            const canvas = document.getElementById('cameraCanvas');
            
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            const ctx = canvas.getContext('2d');
            // Flip horizontally to match mirrored video
            ctx.translate(canvas.width, 0);
            ctx.scale(-1, 1);
            ctx.drawImage(video, 0, 0);
            
            return canvas.toDataURL('image/jpeg', 0.8);
        }
        
        async function captureAndIdentify() {
            const status = document.getElementById('cameraStatus');
            status.textContent = 'üîç Identifying...';
            status.className = 'camera-status';
            
            try {
                const imageData = captureFrame();
                
                const response = await fetch('/api/face/identify', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        image: imageData,
                        session_id: currentSession?.session_id
                    })
                });
                
                const result = await response.json();
                
                if (result.error) {
                    status.textContent = '‚ùå ' + result.error;
                    status.className = 'camera-status error';
                    return;
                }
                
                if (result.recognized) {
                    status.textContent = `‚úÖ Hello ${result.name}! (${Math.round(result.confidence * 100)}% confident)`;
                    status.className = 'camera-status success';
                    
                    // Update user display
                    if (result.user_id) {
                        currentUserId = result.user_id;
                        document.getElementById('userName').textContent = result.name;
                        document.getElementById('userIcon').textContent = 'üë§';
                    }
                    
                    // Announce to Abby
                    askAbby(`You just saw me through the camera. My name is ${result.name}. Say hi!`);
                    
                } else if (result.faces_detected > 0) {
                    status.textContent = 'ü§î I see a face but don\'t recognize you. Click "Learn My Face" to teach me!';
                    status.className = 'camera-status';
                } else {
                    status.textContent = 'üëÄ No face detected. Make sure your face is visible and well-lit.';
                    status.className = 'camera-status';
                }
                
            } catch (e) {
                status.textContent = '‚ùå Error: ' + e.message;
                status.className = 'camera-status error';
            }
        }
        
        async function captureAndLearn() {
            // Prompt for name if not already identified
            let userId = currentUserId;
            let name = document.getElementById('userName').textContent;
            
            if (userId === 'unknown' || name === "Who's this?") {
                name = prompt('What should I call you?');
                if (!name) return;
                
                userId = name.toLowerCase().replace(/[^a-z0-9]/g, '_');
            }
            
            const status = document.getElementById('cameraStatus');
            status.textContent = 'üß† Learning your face...';
            status.className = 'camera-status';
            
            try {
                const imageData = captureFrame();
                
                const response = await fetch('/api/face/learn', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        user_id: userId,
                        name: name,
                        image: imageData
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    status.textContent = `‚úÖ ${result.message}`;
                    status.className = 'camera-status success';
                    
                    // Update user
                    currentUserId = userId;
                    document.getElementById('userName').textContent = name;
                    
                    // Reload known faces list
                    loadKnownFaces();
                    
                    // Announce
                    askAbby(`I just taught you to recognize my face. My name is ${name}. Now you'll know it's me!`);
                    
                } else {
                    status.textContent = '‚ùå ' + (result.error || 'Learning failed');
                    status.className = 'camera-status error';
                }
                
            } catch (e) {
                status.textContent = '‚ùå Error: ' + e.message;
                status.className = 'camera-status error';
            }
        }
        
        async function loadKnownFaces() {
            const list = document.getElementById('knownFacesList');
            
            try {
                const response = await fetch('/api/face/status');
                const status = await response.json();
                
                if (!status.available) {
                    list.innerHTML = '<em>Face recognition not available</em>';
                    return;
                }
                
                if (status.users && status.users.length > 0) {
                    list.innerHTML = status.users.map(user => `
                        <div class="known-face-item">
                            <span class="face-icon">üë§</span>
                            <div class="face-info">
                                <div class="face-name">${user.name}</div>
                                <div class="face-samples">${user.samples} sample${user.samples !== 1 ? 's' : ''}</div>
                            </div>
                        </div>
                    `).join('');
                } else {
                    list.innerHTML = '<em>No faces learned yet</em>';
                }
                
            } catch (e) {
                list.innerHTML = '<em>Could not load faces</em>';
            }
        }
        
        // ============ CONTINUOUS VISUAL AWARENESS (LOCAL PROCESSING) ============
        
        async function toggleVisualAwareness() {
            const toggle = document.getElementById('visionToggle');
            const cameraBtn = document.getElementById('cameraBtn');
            
            if (toggle.checked) {
                await startVisualAwareness();
                cameraBtn.classList.add('watching');
            } else {
                stopVisualAwareness();
                cameraBtn.classList.remove('watching');
            }
        }
        
        async function startVisualAwareness() {
            if (visualAwarenessActive) return;
            
            const statusDiv = document.getElementById('visionStatus');
            const statusText = document.getElementById('visionStatusText');
            
            // Make sure camera is running
            if (!cameraStream) {
                await openCameraModal();
            }
            
            visualAwarenessActive = true;
            statusDiv.className = 'vision-status watching';
            statusText.textContent = 'Watching... (local processing)';
            document.getElementById('visionStatus').querySelector('.icon').textContent = 'üëÅÔ∏è';
            
            console.log('üëÅÔ∏è Visual awareness STARTED - all processing is LOCAL');
            
            // Start periodic frame analysis
            visionInterval = setInterval(analyzeCurrentFrame, 2000);  // Every 2 seconds
            
            // Do first analysis immediately
            analyzeCurrentFrame();
        }
        
        function stopVisualAwareness() {
            if (!visualAwarenessActive) return;
            
            visualAwarenessActive = false;
            
            if (visionInterval) {
                clearInterval(visionInterval);
                visionInterval = null;
            }
            
            const statusDiv = document.getElementById('visionStatus');
            const statusText = document.getElementById('visionStatusText');
            statusDiv.className = 'vision-status not-watching';
            statusText.textContent = 'Not watching';
            document.getElementById('visionStatus').querySelector('.icon').textContent = '‚è∏Ô∏è';
            
            // Clear face boxes
            const overlay = document.getElementById('cameraOverlay');
            overlay.innerHTML = '';
            
            // Clear context
            visualContext = '';
            lastSeenPeople = [];
            
            console.log('üëÅÔ∏è Visual awareness STOPPED');
        }
        
        async function analyzeCurrentFrame() {
            if (!visualAwarenessActive || !cameraStream) return;
            
            try {
                const imageData = captureFrame();
                
                const response = await fetch('/api/vision/analyze', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ image: imageData })
                });
                
                const result = await response.json();
                
                if (result.error) {
                    console.warn('Vision analysis error:', result.error);
                    return;
                }
                
                // Update face boxes overlay
                updateFaceBoxes(result.faces || []);
                
                // Update status
                const statusText = document.getElementById('visionStatusText');
                const statusDiv = document.getElementById('visionStatus');
                
                if (result.faces_detected > 0) {
                    const names = result.faces.map(f => f.name).filter(n => n !== 'Unknown');
                    const unknownCount = result.faces.filter(f => f.name === 'Unknown').length;
                    
                    let text = '';
                    if (names.length > 0) {
                        text = `Seeing: ${names.join(', ')}`;
                        if (unknownCount > 0) text += ` + ${unknownCount} unknown`;
                    } else {
                        text = `Seeing ${unknownCount} face${unknownCount > 1 ? 's' : ''} (not recognized)`;
                    }
                    
                    // Add expression info
                    for (const face of result.faces) {
                        if (face.name !== 'Unknown' && face.expression?.mood) {
                            text += ` ‚Ä¢ ${face.name}: ${getExpressionEmoji(face.expression.mood)}`;
                        }
                    }
                    
                    statusText.textContent = text;
                    statusDiv.className = 'vision-status watching';
                } else {
                    statusText.textContent = 'Watching... (no one visible)';
                }
                
                // Track entries/exits
                const currentPeople = result.people_present || [];
                const newPeople = currentPeople.filter(p => !lastSeenPeople.includes(p) && p !== 'Unknown');
                const leftPeople = lastSeenPeople.filter(p => !currentPeople.includes(p) && p !== 'Unknown');
                
                // Announce arrivals (but don't interrupt conversation)
                if (newPeople.length > 0 && !isBusy) {
                    console.log('üëã New people appeared:', newPeople);
                    // Update user identity if we recognize them
                    if (newPeople.length === 1 && currentUserId === 'unknown') {
                        const arrivedUser = newPeople[0].toLowerCase().replace(/[^a-z0-9]/g, '_');
                        // Don't auto-switch, just notify
                        document.getElementById('cameraStatus').textContent = 
                            `üëã Hi ${newPeople[0]}! I see you.`;
                    }
                }
                
                if (leftPeople.length > 0 && !isBusy) {
                    console.log('üëã People left:', leftPeople);
                }
                
                lastSeenPeople = currentPeople;
                
                // Store visual context for conversations
                visualContext = result.faces_detected > 0 ? 
                    `[Visual context: ${getVisualDescription(result)}]` : '';
                
            } catch (e) {
                console.warn('Frame analysis error:', e);
            }
        }
        
        function updateFaceBoxes(faces) {
            const overlay = document.getElementById('cameraOverlay');
            const video = document.getElementById('cameraPreview');
            
            // Clear existing boxes
            overlay.innerHTML = '';
            
            if (!video.videoWidth) return;
            
            const scaleX = overlay.clientWidth / video.videoWidth;
            const scaleY = overlay.clientHeight / video.videoHeight;
            
            for (const face of faces) {
                const loc = face.location;
                if (!loc) continue;
                
                // Create face box (mirror horizontally to match video)
                const box = document.createElement('div');
                box.className = `face-box live ${face.name === 'Unknown' ? 'unknown' : ''}`;
                
                // Calculate mirrored position
                const mirroredLeft = video.videoWidth - loc.right;
                const mirroredRight = video.videoWidth - loc.left;
                
                box.style.left = `${mirroredLeft * scaleX}px`;
                box.style.top = `${loc.top * scaleY}px`;
                box.style.width = `${(mirroredRight - mirroredLeft) * scaleX}px`;
                box.style.height = `${(loc.bottom - loc.top) * scaleY}px`;
                box.style.display = 'block';
                
                // Add name label
                const label = document.createElement('div');
                label.className = 'face-label';
                label.textContent = face.name !== 'Unknown' ? 
                    `${face.name} ${getExpressionEmoji(face.expression?.mood)}` : 
                    '?';
                box.appendChild(label);
                
                // Add confidence badge for known faces
                if (face.name !== 'Unknown' && face.confidence > 0) {
                    const badge = document.createElement('div');
                    badge.className = 'expression-badge';
                    badge.textContent = `${Math.round(face.confidence * 100)}%`;
                    box.appendChild(badge);
                }
                
                overlay.appendChild(box);
            }
        }
        
        function getExpressionEmoji(mood) {
            const moods = {
                'happy': 'üòä',
                'smiling': 'üòä',
                'tired': 'üò¥',
                'surprised': 'üòÆ',
                'neutral': 'üòê'
            };
            return moods[mood] || '';
        }
        
        function getVisualDescription(analysis) {
            const parts = [];
            
            const names = (analysis.faces || []).filter(f => f.name !== 'Unknown').map(f => f.name);
            const unknownCount = (analysis.faces || []).filter(f => f.name === 'Unknown').length;
            
            if (names.length > 0) {
                parts.push(`I can see ${names.join(' and ')}`);
            }
            if (unknownCount > 0) {
                parts.push(`${unknownCount} unrecognized person${unknownCount > 1 ? 's' : ''}`);
            }
            
            // Expressions
            for (const face of analysis.faces || []) {
                if (face.expression?.smiling) {
                    parts.push(`${face.name} is smiling`);
                }
            }
            
            // Looking at camera
            const looking = (analysis.faces || []).filter(f => f.looking_at_camera).map(f => f.name);
            if (looking.length > 0) {
                parts.push(`${looking.join(' and ')} ${looking.length === 1 ? 'is' : 'are'} looking at me`);
            }
            
            return parts.join('. ');
        }
        
        // Get visual context for injection into conversations
        function getVisualContextForConversation() {
            return visualContext;
        }
        
        // Initialize face recognition check
        checkFaceRecognition();
        
        // ============ USER IDENTITY / PRESENCE ============
        let currentSession = null;
        let availableUsers = [];
        let currentUserId = 'unknown';
        
        async function initSession() {
            try {
                // Try to get existing session from localStorage
                const existingSessionId = localStorage.getItem('abby_session_id');
                
                const response = await fetch('/api/presence/session', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ session_id: existingSessionId })
                });
                
                const data = await response.json();
                currentSession = data;
                availableUsers = data.available_users || [];
                currentUserId = data.user_id;
                
                // Save session ID for persistence
                localStorage.setItem('abby_session_id', data.session_id);
                
                // Update UI
                updateUserDisplay();
                
                // If already identified, show greeting
                if (data.is_identified && data.greeting) {
                    document.getElementById('welcomeMsg').textContent = data.greeting;
                }
                
                console.log('Session initialized:', data.session_id, 'User:', data.display_name);
            } catch (e) {
                console.error('Failed to init session:', e);
            }
        }
        
        function updateUserDisplay() {
            const btn = document.getElementById('userSelectBtn');
            const icon = document.getElementById('userIcon');
            const name = document.getElementById('userName');
            
            if (currentUserId === 'unknown') {
                icon.textContent = 'üë§';
                name.textContent = "Who's this?";
                btn.classList.remove('identified');
            } else if (currentUserId === 'organic_abby') {
                icon.textContent = 'üíï';
                name.textContent = 'Organic Abby';
                btn.classList.add('identified');
            } else if (currentUserId === 'boyfriend') {
                icon.textContent = 'üî•';
                name.textContent = 'The Boyfriend';
                btn.classList.add('identified');
            } else {
                icon.textContent = '‚ú®';
                name.textContent = currentSession?.display_name || 'User';
                btn.classList.add('identified');
            }
        }
        
        function openUserModal() {
            const modal = document.getElementById('userModal');
            modal.classList.add('active');
            renderUserOptions();
        }
        
        function closeUserModal() {
            document.getElementById('userModal').classList.remove('active');
        }
        
        function renderUserOptions() {
            const container = document.getElementById('userOptions');
            container.innerHTML = '';
            
            // Hardcoded known users with descriptions
            const knownUsers = [
                { 
                    id: 'organic_abby', 
                    name: 'Organic Abby', 
                    desc: 'The creator, the original, the real deal üíï',
                    icon: 'üë∏',
                    class: 'organic'
                },
                { 
                    id: 'boyfriend', 
                    name: 'The Boyfriend', 
                    desc: 'Chaos incarnate, but we love him üî•',
                    icon: 'üòà',
                    class: 'boyfriend'
                }
            ];
            
            knownUsers.forEach(user => {
                const div = document.createElement('div');
                div.className = `user-option ${user.class} ${currentUserId === user.id ? 'selected' : ''}`;
                div.onclick = () => selectUser(user.id);
                div.innerHTML = `
                    <div class="user-option-icon">${user.icon}</div>
                    <div class="user-option-info">
                        <div class="user-option-name">${user.name}</div>
                        <div class="user-option-desc">${user.desc}</div>
                    </div>
                `;
                container.appendChild(div);
            });
        }
        
        async function selectUser(userId) {
            if (!currentSession) return;
            
            try {
                const response = await fetch('/api/presence/identify', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        session_id: currentSession.session_id,
                        user_id: userId
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    currentUserId = userId;
                    currentSession.user_id = userId;
                    currentSession.display_name = result.display_name;
                    
                    updateUserDisplay();
                    closeUserModal();
                    
                    // Show greeting
                    if (result.greeting) {
                        addMessage(result.greeting, 'assistant');
                    }
                } else {
                    console.error('Failed to identify:', result.error);
                }
            } catch (e) {
                console.error('Failed to select user:', e);
            }
        }
        
        // Initialize session on page load
        document.addEventListener('DOMContentLoaded', () => {
            initSession();
        });
    </script>
    
    <!-- User Selection Modal -->
    <div class="user-modal" id="userModal">
        <div class="user-modal-content">
            <h2>üëã Who's there?</h2>
            <p class="user-modal-subtitle">Let me know who I'm talking to so I can personalize our chat!</p>
            <div id="userOptions"></div>
            <button class="user-modal-close" onclick="closeUserModal()">Maybe Later</button>
        </div>
    </div>
</body>
</html>
